{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mxYWD7yp5iz",
        "outputId": "9fe17259-e248-4f35-9190-d97ed21043bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.20.0-py3-none-any.whl (292 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置OpenAI KEY环境变量\n",
        "import os\n",
        "import getpass\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdHsAh2zs5MQ",
        "outputId": "aea23b84-6468-4b21-96b2-22dcc8eed55b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 本示例，我们将展示如何使用OpenAI API进行微调OpenAI的模型：\n",
        "\n",
        "PS：\n",
        "\n",
        "1）微调的数据集合微调后的模型必须保存到OpenAI的服务器上，像调用OpenAI模型一样调用微调后的模型，因此还是需要付费的；\n",
        "\n",
        "2）只能微调ada、babbage、curie和davinci基础模型（未经过RLHF），不能微调InstructGPT系列\n",
        "\n"
      ],
      "metadata": {
        "id": "n0xkMG12utkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "def chat_completion(prompt, model=\"gpt-4\", temperature=0):\n",
        "    res = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    print(res.choices[0].message.content)\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "myhXCqtus3WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "本案例我们将为一家电子邮件营销机构制作一个文本生成工具。\n",
        "\n",
        "我们使用GPT-3.5 Turbo模型来生成数据（**工作中应该有专家进行标注**），并使用这些数据微调模型"
      ],
      "metadata": {
        "id": "Hc_Xi2ZLvSLB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K549YbyWp5jp"
      },
      "outputs": [],
      "source": [
        "# 首先定义3个列表，分别对应商店类型、商店所在城市和商店规模\n",
        "l_sector = ['Grocery Stores', 'Restaurants', 'Fast Food Restaurants', 'Pharmacies', 'Service Stations (Fuel)', 'Electronics Stores']\n",
        "l_city = ['Brussels', 'Paris', 'Berlin']\n",
        "l_size = ['small', 'medium', 'large']\n",
        "\n",
        "# 定义生成合成数据的Prompt\n",
        "f_prompt = \"\"\"\n",
        "Role: You are an expert content writer with extensive direct marketing experience. You have strong writing skills, creativity, adaptability to different tones and styles, and a deep understanding of audience needs and preferences for effective direct campaigns.\n",
        "Context: You have to write a short message in maximum 2 sentences for a direct marketing campaign to sell a new e-commerce payment service to stores.\n",
        "The target stores have the three following characteristics:\n",
        "- The sector of activity: {sector}\n",
        "- The city where the stores are located: {city}\n",
        "- The size of the stores: {size}\n",
        "Task: Writes the short message for the direct marketing campaign. To write this message, use your skills defined in your role! It is very important that the messages you produce take into account the product you want to sell and the characteristics of the store you want to write to.\n",
        "\"\"\"\n",
        "\n",
        "# 构造微调数据集\n",
        "f_sub_prompt = \"{sector}, {city}, {size}\"\n",
        "\n",
        "#\n",
        "df = pd.DataFrame()\n",
        "for sector in l_sector:\n",
        " for city in l_city:\n",
        "  for size in l_size:\n",
        "   for i in range(3): ## 3 times each\n",
        "    prompt = f_prompt.format(sector=sector, city=city, size=size)\n",
        "    sub_prompt = f_sub_prompt.format(sector=sector, city=city, size=size)\n",
        "\n",
        "    response_txt = chat_completion(prompt, model='gpt-3.5-turbo', temperature=1)\n",
        "\n",
        "    # sub_prompt和response_txt添加到out_openai_completion.csv文件中，作为微调数据集\n",
        "    new_row = {\n",
        "      'prompt':sub_prompt,\n",
        "      'completion':response_txt}\n",
        "    new_row = pd.DataFrame([new_row])\n",
        "    df = pd.concat([df, new_row], axis=0, ignore_index=True)\n",
        "\n",
        "df.to_csv(\"out_openai_completion.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 接下来，上传数据到OpenAI服务器\n",
        "\n",
        "微调数据需要是JSONL格式，OpenAI提供了一个工具，可以把各种文件格式（CSV、TSV、XLSX、JSON或者JSONL）作为输入，**只要他们包含提示词和文本补全列**\n",
        "\n",
        "## CSV格式转换为JSONL"
      ],
      "metadata": {
        "id": "WQCuxye8ywSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f out_openai_completion.csv\n",
        "# 微调结束后会生成out_openai_completion_prepared.jsonl文件"
      ],
      "metadata": {
        "id": "QB8a424Ky6tU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 上传微调数据集并进行微调"
      ],
      "metadata": {
        "id": "pyzSeIP709EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ft_file = openai.File.create(file=open(\"out_openai_completion_prepared.jsonl\", \"rb\"), purpose=\"fine-tune\") # 微调时，purpose设置为fine-tune。此函数会输出一个字典，可以通过id检索文件\n",
        "# 列出已上传的文件\n",
        "!openai.File.list()\n",
        "openai.FineTune.create(training_file=ft_file[\"id\"], model=\"davinci\", suffix=\"direct_marketing\") # training_file必须格式化为JSONL文件；model是用于微调的模型；suffix最多由40个字符组成的字符串，它将被添加到微调后模型名称中。"
      ],
      "metadata": {
        "id": "OpWxNrh-2jcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.create -t out_openai_completion_prepared.jsonl -m davinci --suffix \"direct_marketing\"\n",
        "# 此时使用Ctrl+C会断开与OpenAI服务器的连接，但不会中断微调过程。要获取正在运行的微调作业，可以使用如下命令：\n",
        "!openai api fine_tunes.follow -i fine_tune_id"
      ],
      "metadata": {
        "id": "7__FvHfc3UJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 下面介绍一些常用的命令：\n",
        "# 1）列出所有微调模型\n",
        "!openai api fine_tunes.list\n",
        "# 2）取消微调作业\n",
        "!openai api fine_tunes.cancel -i fine_tune_id\n",
        "# 3）删除微调作业\n",
        "!openai api fine_tunes.delete -i fine_tune_id"
      ],
      "metadata": {
        "id": "h1iRDXDB40UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用微调后的模型"
      ],
      "metadata": {
        "id": "4GlRnduH6oWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!openai.completion.create(model=\"davinci:ft-book:direct-marketing-2024-04-17-12-12-12\", prompt=\"Hotel, New York, small ->\", max_tokens=100, temperature=0, stop=\"\\n\")"
      ],
      "metadata": {
        "id": "XLz6k4td6vDo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}