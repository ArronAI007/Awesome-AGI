{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFsyON6vpy-D"
      },
      "source": [
        "# langchain+qwen+faiss实现RAG数据之间的隔离\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们在开发RAG增加检索应用时，总会遇到数据隔离的问题，比如，你上传的资料数据，不能让别人检索到，不然会存在数据安全问题。所以我们得为每个用户的数据进行隔离， 他们都不应该看到对方的数据，除非数据已经授权或者分配权限给他们访问。\n",
        "\n",
        "本文主要实现该功能，只有进行了分配权限才能访问数据，该功能在企业或者RAG增强检索当中是比较常用的。\n",
        "\n",
        "## 主要的实现步骤\n",
        "不清楚RAG增强检索的可以看之前的文章\n",
        "- 1.先加载文档\n",
        "- 2.对文档数据进行分块\n",
        "- 3.分块之后增加role权限字段，用于过滤权限\n",
        "- 4.在检索文档数据时，会按role的值进行过滤\n",
        "- 5.把过滤好后的文档数据，加上用户提的问题一起发给llm模型处理（通义千问）\n",
        "- 6.LLM处理后，返回结果\n",
        "\n",
        "该功能实现的核心是增加role 权限字段过滤，在用户提问的时候，就分配好了他能检索哪方面的数据。"
      ],
      "metadata": {
        "id": "gikTMF-4lL7_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 一、安装相关依赖包"
      ],
      "metadata": {
        "id": "Kc-ck9MsltBz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lelTYRou9xuh",
        "outputId": "730aad8e-07c9-42de-cb0a-d7d394dc197f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qdrant-client\n",
            "  Downloading qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypdfium2\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.2)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting dashscope\n",
            "  Downloading dashscope-1.23.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (1.71.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.0.2)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (5.29.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.11.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant-client) (2.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain_openai)\n",
            "  Downloading langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from dashscope) (1.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain_openai) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain_openai) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dashscope-1.23.2-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.58-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, pypdfium2, pypdf, portalocker, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, backoff, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, dashscope, qdrant-client, langchain-core, langchain_openai, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.56\n",
            "    Uninstalling langchain-core-0.3.56:\n",
            "      Successfully uninstalled langchain-core-0.3.56\n",
            "Successfully installed backoff-2.2.1 dashscope-1.23.2 dataclasses-json-0.6.7 faiss-cpu-1.11.0 httpx-sse-0.4.0 langchain-core-0.3.58 langchain_community-0.3.23 langchain_openai-0.3.16 marshmallow-3.26.1 mypy-extensions-1.1.0 portalocker-2.10.1 pydantic-settings-2.9.1 pypdf-5.4.0 pypdfium2-4.30.1 python-dotenv-1.1.0 qdrant-client-1.14.2 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install qdrant-client pypdfium2 backoff openai langchain_openai langchain langchain_community dashscope pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yXHWECMAuO5"
      },
      "source": [
        "# 二、导入相关依赖包"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ejo6uOsB-ne2"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_models.tongyi import ChatTongyi\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings import DashScopeEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client.http import models as rest\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
        "\n",
        "import os\n",
        "\n",
        "qwen_api_key = \"你的通义千问API-KEY\"\n",
        "os.environ[\"DASHSCOPE_API_KEY\"] = qwen_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 三、构建向量化对象"
      ],
      "metadata": {
        "id": "NMG8xzQvmB5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = DashScopeEmbeddings(\n",
        "    model=\"text-embedding-v1\", dashscope_api_key=qwen_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "OafzuQpYdhPJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 四、定义读取文档函数，并进行文档分块\n",
        "读取文档数据的方法，并定义角色metadata.roles字段，分块后的文档都会有该字段，表示这个文档有哪些角色可以访问。"
      ],
      "metadata": {
        "id": "ynGrHVQpmFkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readPdfData(documents):\n",
        "    page = []\n",
        "\n",
        "    for document_path, roles in documents.items():\n",
        "        # 读取当前目录下文件名为test.pdf和byd.pdf的文件\n",
        "        pdf_loader = PyPDFLoader(document_path, extract_images=True)\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        "        )\n",
        "\n",
        "        loaded_documents = pdf_loader.load_and_split()\n",
        "\n",
        "        for doc in loaded_documents:\n",
        "            doc.metadata[\"roles\"] = roles\n",
        "\n",
        "        # 对文档进行分块\n",
        "        split_documents = text_splitter.split_documents(loaded_documents)\n",
        "        page.extend(split_documents)\n",
        "    return page"
      ],
      "metadata": {
        "id": "KAXMQna8dhRv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 五、切换到Google Colab数据目录"
      ],
      "metadata": {
        "id": "3XG3ORKDmXp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hsdg2lehjdG4",
        "outputId": "ed6c99bf-d7f7-4a38-edf5-cd9adb728bf9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/drive/My Drive/Colab/RAG/LangChain_RAG/\"\n",
        "os.chdir(path)"
      ],
      "metadata": {
        "id": "FhTxNRspjd__"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "读取llm文件，并设置角色过滤字段roles为ali，意思是检索文档数据时，参数中roles字段包含ali 的时候才能访问这个文档数据"
      ],
      "metadata": {
        "id": "Op5kRnt8mQZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_documents1 = readPdfData({\"Data/llm.pdf\": \"llm\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHrDXUEodhUF",
        "outputId": "8798d2d1-0a38-44d4-ae0d-95ac5fc91f09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 六、构建faiss矢量数据库对象\n",
        "\n",
        "存储数据的集合名称为my_documents，构建的方式是把文档数据加载到内存，仅用于测试，想构成存储到磁盘或者使用本地服务器的话参考官方提供的例子。"
      ],
      "metadata": {
        "id": "A-YQHKrumlra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faiss = FAISS.from_documents(\n",
        "    split_documents1,\n",
        "    embeddings,\n",
        ")"
      ],
      "metadata": {
        "id": "sAY2x1OTdhW9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 七、在之前的集合追加文档\n",
        "读取maotai文件，并也为该文件分配了maotai权限"
      ],
      "metadata": {
        "id": "pwh37jiymt1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 该文档为茅台的财报，可多个pdf\n",
        "documents2 = {\n",
        "    \"Data/maotai.pdf\": \"maotai\",\n",
        "}\n",
        "\n",
        "split_documents2 = readPdfData(documents2)\n",
        "\n",
        "# 追加新的文档\n",
        "faiss.add_documents(split_documents2, batch_size=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPUBZe-9e-oQ",
        "outputId": "70c16970-6cac-4756-cde0-214017fe6296"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['71feba31-7495-4553-92e7-f36d7feacabf']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 八、定义检索对象\n",
        "检索文档数据库时，只会检索metadata.roles字段为maotai、ali的数据，其它数据都会过滤掉。"
      ],
      "metadata": {
        "id": "SM4VAcZYm0p_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_roles = [\"maotai\", \"llm\"]\n",
        "\n",
        "faiss_retriever = faiss.as_retriever(\n",
        "    search_kwargs={\n",
        "        \"filter\": {\"roles\": \"maotai\"}\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "vHqgn4Pde-q2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 九、构建大语言模型对象"
      ],
      "metadata": {
        "id": "_oO6U3zVm_Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatTongyi(model=\"qwen-plus\")"
      ],
      "metadata": {
        "id": "J3hJLVsre-te"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 十、向qwen模型提问\n",
        "根据用户提的问题，先去文档数据库中检索， 检索时会按我们定义的user_roles过滤掉数据，拿到相似的结果后，会根据用户的问题+相似的结果，一起发送给qwen模型，模型处理后会把最终的结果返回给我们。"
      ],
      "metadata": {
        "id": "zSb-Mfx0nDRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "Question: {question}\n",
        "使用源回答问题。如果没有答案，请说\"文本中没有答案\".\n",
        "\n",
        "Source: {context}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "# 构建提问模板\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# 构建过滤请求对象\n",
        "retrieval_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=faiss_retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")\n",
        "\n",
        "# 发送请求\n",
        "response = retrieval_qa.invoke({\"query\": \"贵州茅台?\"})\n",
        "print(response[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5duzS0Ie-wW",
        "outputId": "15a8b300-60dc-479a-b282-7557b9351dbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "贵州茅台是中国著名的白酒⽣产企业，根据2023年第三季度报告，其主要财务和股东信息如下：\n",
            "\n",
            "1. **营业收⼊**：达到103,268,354,688.44元，同⽐增⻓18.48%。\n",
            "2. **净利润**：归属于上市公司股东的净利润为52,876,217,064.12元，同⽐增⻓19.09%。\n",
            "3. **流动资产**：\n",
            "   - 货币资⾦为70,641,010,014.72元。\n",
            "   - 拆出资⾦为95,625,606,731.69元。\n",
            "4. **负债和所有者权益总计**：262,076,424,771.47元，其中所有者权益合计为225,018,799,759.41元。\n",
            "\n",
            "此外，贵州茅台的前10名⽆限售条件股东中，中国贵州茅台酒⼚（集团）有限责任公司是最⼤股东，持有679,211,576股。其他重要股东包括⾹港中央结算有限公司和贵州省国有资本运营有限责任公司等。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "还是提同样的问题，我们把该访问maotai.pdf的角色授权roles字段改为a，这里我们就不会访问到数据了，因为我们没有maotai权限，我们定义了只有这个权限才能访问该文件。"
      ],
      "metadata": {
        "id": "63uK7T91nati"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 改为a权限\n",
        "user_roles = [\"a\", \"ali\"]\n",
        "\n",
        "faiss_retriever2 = faiss.as_retriever(\n",
        "    search_kwargs={\n",
        "        \"filter\": {\"roles\": \"llm\"}\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "XMZBD0Ake-y8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "Question: {question}\n",
        "使用源回答问题。如果没有答案，请说\"文本中没有答案\".\n",
        "\n",
        "Source: {context}\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "# 构建提问模板\n",
        "prompt = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# 构建过滤请求对象\n",
        "retrieval_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=faiss_retriever2,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt},\n",
        ")\n",
        "\n",
        "# 发送请求\n",
        "response = retrieval_qa.invoke({\"query\": \"贵州茅台?\"})\n",
        "print(response[\"result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgwzHINzkRH8",
        "outputId": "4f720d5b-ee7a-4483-88bf-e308feb397f0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "文本中没有答案。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "当用户权限为maotai的时候，可以正确输出答案；当权限为llm，query：\"贵州茅台?\"不能正确回答，从而实现了权限控制。"
      ],
      "metadata": {
        "id": "nCOs66PDjrrT"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}