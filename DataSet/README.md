 ## Open LLM datasets for pre-training

| Name | Release Date | Paper/Blog | Dataset | Tokens (T) | License |
| --- | --- | --- | --- | --- | ---- | 
| Anthropic HH |  |  | [Anthropic HH](https://huggingface.co/datasets/Anthropic/hh-rlhf) |  |  | 
| HC3 |  | [How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection](https://arxiv.org/abs/2301.07597) | [HC3 数据集](https://huggingface.co/Hello-SimpleAI) |  |  | 
| koala-test-set |  |  | [koala-test-set](https://github.com/arnav-gudibande/koala-test-set) |  |  | 
| MTP（massive text pairs） | 2023/09 | [智源发布超3亿对面向中英文语义向量模型训练数据集](https://mp.weixin.qq.com/s/50U3blK0ROZSoNFl75TWHw) | [BAAI-MTP](https://data.baai.ac.cn/details/BAAI-MTP) | 1.3 |  | 
| OpenAI WebGPT |  |  | [OpenAI WebGPT](https://huggingface.co/datasets/openai/webgpt_comparisons) |  |  | 
| OpenAI Summarization |  |  | [OpenAI Summarization](https://huggingface.co/datasets/openai/summarize_from_feedback) |  |  | 
| RedPajama | 2023/04 | [RedPajama, a project to create leading open-source models, starts by reproducing LLaMA training dataset of over 1.2 trillion tokens](https://www.together.xyz/blog/redpajama) | [RedPajama-Data](https://github.com/togethercomputer/RedPajama-Data) |  |  | 
| ShareGPT |  |  | [ShareGPT](https://sharegpt.com/) |  |  | 
| starcoderdata | 2023/05 | [StarCoder: A State-of-the-Art LLM for Code](https://huggingface.co/blog/starcoder) | [starcoderdata](https://huggingface.co/datasets/bigcode/starcoderdata) |  0.25 | Apache 2.0 |
| Stanford Alpaca |  | [Stanford Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html) | [Alpaca Dataset](https://github.com/gururise/AlpacaDataCleaned) |  |  | 

---

 ## Open LLM datasets for instruction-tuning

| Name | Release Date | Paper/Blog | Dataset | Tokens (T) | License |
| --- | --- | --- | --- | --- | --- | 
| databricks-dolly-15k | 2023/04 | [Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm) |  [databricks-dolly-15k](https://huggingface.co/datasets/databricks/databricks-dolly-15k) | 15 |  CC BY-SA-3.0 |
| MPT-7B-Instruct | 2023/05 | [Introducing MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs](https://www.mosaicml.com/blog/mpt-7b) | [dolly_hhrlhf](https://huggingface.co/datasets/mosaicml/dolly_hhrlhf) | 59 | CC BY-SA-3.0 |
| OIG (Open Instruction Generalist)   | 2023/03 | [THE OIG DATASET](https://laion.ai/blog/oig-dataset/) | [OIG](https://huggingface.co/datasets/laion/OIG) | 44,000 | Apache 2.0 |
| UltraFeedback：大规模、多样化、细粒度的偏好数据集
 |  |  | [UltraFeedback Code](https://github.com/OpenBMB/UltraFeedback) |  |  | 
|  UltraChat：高质量对话数据集，包含 150 余万条多轮指令数据|  |  | [UltraChat Code](https://github.com/thunlp/UltraChat) |  |  | 

---

 ## Open LLM datasets for alignment-tuning

| Name | Release Date | Paper/Blog | Dataset | Tokens (T) | License |
| --- | --- | --- | --- | --- | ---- | 
| OpenAssistant Conversations Dataset | 2023/04 | [OpenAssistant Conversations - Democratizing Large Language Model Alignment](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view) | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1) | 161 | Apache 2.0 |

---

## LLM Evaluation Benchmark

| Name | Release Date |  Paper/Blog | Dataset | Samples (K) | License |
| --- | --- | --- | --- | --- | ---- |
| C-Eval | --- | --- | [C-Eval](https://cevalbenchmark.com/index.html) | --- | ---- |
| Gaokao | --- | --- | [Gaokao](https://github.com/OpenLMLab/GAOKAO-Bench) | --- | ---- |
| AGIEval | --- | --- | [AGIEval](https://github.com/microsoft/AGIEval) | --- | ---- |
| MMLU | --- | --- | [MMLU](https://arxiv.org/abs/2009.03300) | --- | ---- |
| LawBench | --- | [LawBench: Benchmarking Legal Knowledge of Large Language Models](https://arxiv.org/pdf/2309.16289.pdf) | [LawBench Code](https://github.com/open-compass/LawBench) | --- | ---- |
| --- | --- | --- | --- | --- | ---- |
| --- | --- | --- | --- | --- | ---- |
| --- | --- | --- | --- | --- | ---- |
| --- | --- | --- | --- | --- | ---- |
| --- | --- | --- | --- | --- | ---- |



### LLM DataSets

Some examples of **DataSets** as follows：

| Description| Paper | Code | Blog |
| --- | --- | --- | --- |  
| 一篇关于LLM指令微调的综述 | [paper](https://arxiv.org/pdf/2308.10792.pdf) |  | [blog](https://mp.weixin.qq.com/s/7pqBvgF1BWDFxP5hajmBNw) |  
| 智源研究院发布国内首个大规模、可商用中文开源指令数据集COIG：最大规模中文多任务指令集，上新千个中文数据集 | [paper](https://arxiv.org/pdf/2304.07987.pdf) |  | [blog](https://mp.weixin.qq.com/s/PvJa8dPHk6aGEv1G1B3PUw)，[COIG-PC数据下载地址](https://huggingface.co/datasets/BAAI/COIG-PC)，[COIG数据下载地址](https://huggingface.co/datasets/BAAI/COIG) |  
| 总结当前开源可用的Instruct/Prompt Tuning数据 |  |  | [blog](https://mp.weixin.qq.com/s/vDbTJo3F7sy3-NY8xxg8jw) |  
| GPT-4平替版：MiniGPT-4，支持图像理解和对话，现已开源 |  |  | [dataset](https://drive.google.com/file/d/1nJXhoEcy3KTExr17I7BXqY5Y9Lx_-n-9/view) |  
| 多模态C4：一个开放的、10亿规模的、与文本交错的图像语料库 | [paper](https://arxiv.org/abs/2304.06939) | [code](https://github.com/allenai/mmc4) |  |  
| Mind2Web: 首个全面衡量大模型上网能力的数据集 |  |  | [blog](https://mp.weixin.qq.com/s/vge4CJbBfLXFIYYyNC12Hw) |  
| 该数据集是一个由人工生成、人工注释的助理式对话语料库，覆盖了广泛的主题和写作风格，由 161443 条消息组成，分布在 66497 个会话树中，使用 35 种不同的语言。该语料库是全球众包工作的产物，涉及超过 13500 名志愿者。为了证明 OpenAssistant Conversations 数据集的有效性，该研究还提出了一个基于聊天的助手 OpenAssistant，其可以理解任务、与第三方系统交互、动态检索信息。 | [paper](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view ) | [code](https://github.com/LAION-AI/Open-Assistant) | [dataset](https://huggingface.co/datasets/OpenAssistant/oasst1) |  
| 为了让Panda LLM在中文数据集上获得强大的性能，作者使用了强大的指令微调instruction-tuning技术，将LLaMA基础模型在五个开源的中文数据集进行混合训练，其中包括来自各种语言领域的1530万个样本，例如维基百科语料，新闻语料，百科问答语料，社区问答语料，和翻译语料。 |  |  | [blog](https://mp.weixin.qq.com/s/IsWSPAvwgT263wjO7TYTZQ) |  
| RedPajama开源项目｜复制超过1.2万亿个令牌的LLaMA训练数据集 |  | [code](https://github.com/togethercomputer/RedPajama-Data) | [原始blog](https://www.together.xyz/blog/redpajama)，[中文blog](https://hub.baai.ac.cn/view/25485)，[dataset](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T) |  








