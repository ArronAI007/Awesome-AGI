import streamlit as st
import json
import time
from datetime import datetime
import os

from agents import (
    ReportStructureAgent, FirstSearchAgent, FirstSummaryAgent, 
    ReflectionAgent, ReflectionSummaryAgent, ReportFormattingAgent
)
from state import State, Paragraph
from utils import tavily_search, update_state_with_search_results
from language_utils import detect_language
from dotenv import load_dotenv

load_dotenv()

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Deep Research Agent",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Constants ---
NUM_REFLECTIONS = 2
NUM_RESULTS_PER_SEARCH = 3
CAP_SEARCH_LENGTH = 20000

def run_research_pipeline(topic: str):
    """æ‰§è¡Œå®Œæ•´çš„æ·±åº¦ç ”ç©¶æµç¨‹"""
    
    # åˆå§‹åŒ–çŠ¶æ€
    STATE = State()
    
    st.write(f"å¼€å§‹ç ”ç©¶ä»»åŠ¡: {topic}")
    
    # æ£€æµ‹è¾“å…¥è¯­è¨€
    lang = detect_language(topic)
    st.write(f"æ£€æµ‹åˆ°çš„è¯­è¨€: {lang}")

    # 1. ç”ŸæˆæŠ¥å‘Šç»“æ„
    with st.status("æ­¥éª¤1: ç”ŸæˆæŠ¥å‘Šç»“æ„...", expanded=True) as status:
        try:
            report_structure_agent = ReportStructureAgent(topic)
            STATE = report_structure_agent.mutate_state(STATE)
            status.update(label="æŠ¥å‘Šç»“æ„ç”Ÿæˆå®Œæˆ!", state="complete", expanded=False)
        except Exception as e:
            status.update(label=f"ç”ŸæˆæŠ¥å‘Šç»“æ„å¤±è´¥: {e}", state="error")
            return

    st.info(f"æŠ¥å‘Šç»“æ„ç”Ÿæˆå®Œæˆï¼Œå…±{len(STATE.paragraphs)}ä¸ªæ®µè½")
    with st.expander("æŸ¥çœ‹æŠ¥å‘Šå¤§çº²"):
        for i, p in enumerate(STATE.paragraphs):
            st.markdown(f"**{i+1}. {p.title}**")
            st.write(p.content)

    # åˆå§‹åŒ–å„ä¸ªAgent
    first_search_agent = FirstSearchAgent()
    first_summary_agent = FirstSummaryAgent()
    reflection_agent = ReflectionAgent()
    reflection_summary_agent = ReflectionSummaryAgent()
    report_formatting_agent = ReportFormattingAgent()

    # 2. å¤„ç†æ¯ä¸ªæ®µè½
    for j in range(len(STATE.paragraphs)):
        paragraph_title = STATE.paragraphs[j].title
        st.markdown(f"--- ")
        st.header(f"æ­£åœ¨ç ”ç©¶æ®µè½ {j + 1}/{len(STATE.paragraphs)}: {paragraph_title}")

        with st.container():
            # 2.1 é¦–æ¬¡æœç´¢
            with st.status(f"æ®µè½ {j + 1}: é¦–æ¬¡æœç´¢...", expanded=True) as status:
                try:
                    message = json.dumps({"title": STATE.paragraphs[j].title, "content": STATE.paragraphs[j].content})
                    output = first_search_agent.run(message)
                    search_query = output.get('search_query', 'N/A')
                    st.write(f"ğŸ” æœç´¢æŸ¥è¯¢: {search_query}")
                    
                    search_results = tavily_search(search_query, max_results=NUM_RESULTS_PER_SEARCH)
                    STATE = update_state_with_search_results(search_results, j, STATE)
                    status.update(label="é¦–æ¬¡æœç´¢å®Œæˆ!", state="complete", expanded=False)
                except Exception as e:
                    status.update(label=f"é¦–æ¬¡æœç´¢å¤±è´¥: {e}", state="error")
                    continue

            # 2.2 é¦–æ¬¡æ€»ç»“
            with st.status(f"æ®µè½ {j + 1}: é¦–æ¬¡æ€»ç»“...", expanded=True) as status:
                try:
                    message = {
                        "title": STATE.paragraphs[j].title,
                        "content": STATE.paragraphs[j].content,
                        "search_query": search_results["query"],
                        "search_results": [result["raw_content"][0:CAP_SEARCH_LENGTH] for result in search_results["results"] if result["raw_content"]]
                    }
                    STATE = first_summary_agent.mutate_state(message=json.dumps(message), idx_paragraph=j, state=STATE)
                    status.update(label="é¦–æ¬¡æ€»ç»“å®Œæˆ!", state="complete", expanded=False)
                except Exception as e:
                    status.update(label=f"é¦–æ¬¡æ€»ç»“å¤±è´¥: {e}", state="error")
                    continue
            
            with st.expander("æŸ¥çœ‹é¦–æ¬¡æ€»ç»“"):
                st.write(STATE.paragraphs[j].research.latest_summary)

            # 2.3 åæ€è¿­ä»£
            for i in range(NUM_REFLECTIONS):
                with st.status(f"æ®µè½ {j + 1}: åæ€è¿­ä»£ {i + 1}/{NUM_REFLECTIONS}...", expanded=True) as status:
                    try:
                        message = {"paragraph_latest_state": STATE.paragraphs[j].research.latest_summary,
                                   "title": STATE.paragraphs[j].title,
                                   "content": STATE.paragraphs[j].content}
                        output = reflection_agent.run(message=json.dumps(message))
                        reflection_query = output.get('search_query', 'N/A')
                        st.write(f"ğŸ¤” åæ€ä¸æœç´¢: {reflection_query}")

                        search_results = tavily_search(reflection_query)
                        STATE = update_state_with_search_results(search_results, j, STATE)

                        message = {
                            "title": STATE.paragraphs[j].title,
                            "content": STATE.paragraphs[j].content,
                            "search_query": search_results["query"],
                            "search_results": [result["raw_content"][0:20000] for result in search_results["results"] if result["raw_content"]],
                            "paragraph_latest_state": STATE.paragraphs[j].research.latest_summary
                        }
                        STATE = reflection_summary_agent.mutate_state(message=json.dumps(message), idx_paragraph=j, state=STATE)
                        status.update(label=f"åæ€è¿­ä»£ {i + 1} å®Œæˆ!", state="complete", expanded=False)
                    except Exception as e:
                        status.update(label=f"åæ€è¿­ä»£ {i + 1} å¤±è´¥: {e}", state="error")
                        continue
                
                with st.expander(f"æŸ¥çœ‹ç¬¬ {i+1} æ¬¡åæ€åçš„æ€»ç»“"):
                    st.write(STATE.paragraphs[j].research.latest_summary)

    # 3. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    st.header("ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
    with st.spinner("æ­£åœ¨æ±‡æ€»æ‰€æœ‰ä¿¡æ¯å¹¶ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š..."):
        try:
            report_data = [{"title": paragraph.title, "paragraph_latest_state": paragraph.research.latest_summary} for paragraph in STATE.paragraphs]
            final_report = report_formatting_agent.run(json.dumps(report_data))
        except Exception as e:
            st.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
            return

    st.success("ç ”ç©¶ä»»åŠ¡å®Œæˆ!")
    st.balloons()

    # 4. æ˜¾ç¤ºå¹¶ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
    st.header("æœ€ç»ˆç ”ç©¶æŠ¥å‘Š")
    st.markdown(final_report)

    try:
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        os.makedirs('reports', exist_ok=True)
        report_filename = f"reports/report_{timestamp}.md"
        with open(report_filename, "w", encoding="utf-8") as f:
            f.write(final_report)
        st.sidebar.success(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
    except Exception as e:
        st.sidebar.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

# --- Streamlit UI ---
st.title("Deep Research Agent ğŸ”")
st.sidebar.header("å…³äº")
st.sidebar.info(
    "è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨LLMè¿›è¡Œæ·±åº¦ç ”ç©¶çš„AIä»£ç†ã€‚å®ƒä¼šæ ¹æ®æ‚¨çš„æŸ¥è¯¢ï¼Œ" 
    "è‡ªåŠ¨ç”ŸæˆæŠ¥å‘Šå¤§çº²ã€æœç´¢ä¿¡æ¯ã€è¿›è¡Œå¤šè½®åæ€ï¼Œå¹¶æœ€ç»ˆç”Ÿæˆä¸€ä»½è¯¦ç»†çš„ç ”ç©¶æŠ¥å‘Šã€‚"
)

st.sidebar.header("è®¾ç½®")
# QUERY = st.sidebar.text_input("ç ”ç©¶ä¸»é¢˜", value="è¯·å¸®æˆ‘ç”Ÿæˆä¸€ä»½æ£€ç´¢å¢å¼ºç”ŸæˆRAGçš„ç»¼è¿°")

with st.form("research_form"):
    topic = st.text_input("è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶ä¸»é¢˜", placeholder="ä¾‹å¦‚ï¼šRAGæŠ€æœ¯çš„æœ€æ–°è¿›å±•")
    submitted = st.form_submit_button("å¼€å§‹ç ”ç©¶")

if submitted and topic:
    run_research_pipeline(topic)
elif submitted:
    st.warning("è¯·è¾“å…¥ä¸€ä¸ªç ”ç©¶ä¸»é¢˜ï¼")
