{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86ca556-39e5-4902-a007-df08c06fdbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "class ChatbotState(TypedDict):\n",
    "    messages: List[dict]\n",
    "    user_context: dict\n",
    "    current_intent: str\n",
    "    conversation_history: List[dict]\n",
    "    pending_actions: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66dbc8d7-f936-4426-a3da-44c5b5fb9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "class ConversationState(TypedDict):\n",
    "    messages: List[dict]\n",
    "    user_profile: dict\n",
    "    current_task: Optional[str]\n",
    "    context_memory: dict\n",
    "    requires_human_review: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eec0120-cc75-49f7-9879-f9203ddb25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def intent_classifier(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"Classify user intent and update state accordingly.\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Classify the user's intent from their message. Categories: question, request, complaint, compliment, other\"),\n",
    "        (\"human\", \"{user_message}\")\n",
    "    ])\n",
    "    \n",
    "    last_message = state[\"messages\"][-1][\"content\"]\n",
    "    response = llm.invoke(prompt.format(user_message=last_message))\n",
    "    \n",
    "    state[\"current_task\"] = response.content.strip().lower()\n",
    "    return state\n",
    "\n",
    "def response_generator(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"Generate contextual response based on intent and history.\"\"\"\n",
    "    llm = ChatOpenAI(model=\"gpt-4\")\n",
    "    \n",
    "    context = f\"\"\"\n",
    "    User Intent: {state['current_task']}\n",
    "    Conversation History: {state['context_memory']}\n",
    "    User Profile: {state['user_profile']}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"You are a helpful assistant. Context: {context}\"),\n",
    "        (\"human\", \"{user_message}\")\n",
    "    ])\n",
    "    \n",
    "    last_message = state[\"messages\"][-1][\"content\"]\n",
    "    response = llm.invoke(prompt.format(user_message=last_message))\n",
    "    \n",
    "    # Add AI response to messages\n",
    "    state[\"messages\"].append({\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": response.content\n",
    "    })\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db74a74-c67c-41ed-9899-2ee4a055076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_escalate(state: ConversationState) -> str:\n",
    "    \"\"\"Determine if conversation should be escalated to human agent.\"\"\"\n",
    "    escalation_intents = [\"complaint\", \"complex_request\", \"billing_issue\"]\n",
    "    \n",
    "    if state[\"current_task\"] in escalation_intents:\n",
    "        return \"human_agent\"\n",
    "    elif state[\"requires_human_review\"]:\n",
    "        return \"human_review\"\n",
    "    else:\n",
    "        return \"continue_bot\"\n",
    "\n",
    "def human_escalation_handler(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"Handle escalation to human agents.\"\"\"\n",
    "    state[\"requires_human_review\"] = True\n",
    "    state[\"messages\"].append({\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Escalating to human agent. Please wait for assistance.\"\n",
    "    })\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0562b7ac-7d08-441a-ab91-ee1ccc8c6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chatbot_graph():\n",
    "    # Initialize the graph\n",
    "    workflow = StateGraph(ConversationState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"classify_intent\", intent_classifier)\n",
    "    workflow.add_node(\"generate_response\", response_generator)\n",
    "    workflow.add_node(\"human_escalation\", human_escalation_handler)\n",
    "    \n",
    "    # Define the flow\n",
    "    workflow.set_entry_point(\"classify_intent\")\n",
    "    \n",
    "    # Add conditional edges\n",
    "    workflow.add_conditional_edges(\n",
    "        \"classify_intent\",\n",
    "        should_escalate,\n",
    "        {\n",
    "            \"human_agent\": \"human_escalation\",\n",
    "            \"human_review\": \"human_escalation\",\n",
    "            \"continue_bot\": \"generate_response\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # End points\n",
    "    workflow.add_edge(\"generate_response\", END)\n",
    "    workflow.add_edge(\"human_escalation\", END)\n",
    "    \n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649a4a2c-2516-4bc4-b558-d882ea70d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedMemoryManager:\n",
    "    def __init__(self):\n",
    "        self.conversation_memory = {}\n",
    "        self.user_profiles = {}\n",
    "    \n",
    "    def update_context(self, state: ConversationState) -> ConversationState:\n",
    "        \"\"\"Update long-term memory and context.\"\"\"\n",
    "        user_id = state.get(\"user_id\", \"anonymous\")\n",
    "        \n",
    "        # Update conversation memory\n",
    "        if user_id not in self.conversation_memory:\n",
    "            self.conversation_memory[user_id] = []\n",
    "        \n",
    "        self.conversation_memory[user_id].extend(state[\"messages\"][-2:])\n",
    "        \n",
    "        # Update user profile based on conversation patterns\n",
    "        self.update_user_profile(user_id, state)\n",
    "        \n",
    "        state[\"context_memory\"] = self.conversation_memory[user_id][-10:]  # Keep last 10 exchanges\n",
    "        return state\n",
    "    \n",
    "    def update_user_profile(self, user_id: str, state: ConversationState):\n",
    "        \"\"\"Update user profile based on interaction patterns.\"\"\"\n",
    "        if user_id not in self.user_profiles:\n",
    "            self.user_profiles[user_id] = {\n",
    "                \"preferences\": {},\n",
    "                \"interaction_count\": 0,\n",
    "                \"common_intents\": []\n",
    "            }\n",
    "        \n",
    "        profile = self.user_profiles[user_id]\n",
    "        profile[\"interaction_count\"] += 1\n",
    "        \n",
    "        # Track common intents\n",
    "        current_intent = state.get(\"current_task\")\n",
    "        if current_intent:\n",
    "            profile[\"common_intents\"].append(current_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbd79bd-b66a-4a9c-9042-2dd9a3eaf220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multi_agent_system():\n",
    "    \"\"\"Create a system with specialized agents.\"\"\"\n",
    "    \n",
    "    def route_to_specialist(state: ConversationState) -> str:\n",
    "        \"\"\"Route to appropriate specialist agent.\"\"\"\n",
    "        intent = state[\"current_task\"]\n",
    "        \n",
    "        routing_map = {\n",
    "            \"technical_support\": \"tech_agent\",\n",
    "            \"billing_inquiry\": \"billing_agent\",\n",
    "            \"product_question\": \"product_agent\",\n",
    "            \"general\": \"general_agent\"\n",
    "        }\n",
    "        \n",
    "        return routing_map.get(intent, \"general_agent\")\n",
    "    \n",
    "    # Specialized agent functions\n",
    "    def technical_support_agent(state: ConversationState) -> ConversationState:\n",
    "        \"\"\"Handle technical support queries.\"\"\"\n",
    "        llm = ChatOpenAI(model=\"gpt-4\")\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are a technical support specialist. \n",
    "            Provide detailed, step-by-step solutions for technical issues.\n",
    "            Always ask for clarification if the problem is unclear.\"\"\"),\n",
    "            (\"human\", \"{user_message}\")\n",
    "        ])\n",
    "        \n",
    "        # Implementation details...\n",
    "        return state\n",
    "    \n",
    "    def billing_agent(state: ConversationState) -> ConversationState:\n",
    "        \"\"\"Handle billing and payment queries.\"\"\"\n",
    "        # Implementation for billing-specific logic\n",
    "        return state\n",
    "    \n",
    "    # Build multi-agent graph\n",
    "    workflow = StateGraph(ConversationState)\n",
    "    \n",
    "    workflow.add_node(\"intent_router\", intent_classifier)\n",
    "    workflow.add_node(\"tech_agent\", technical_support_agent)\n",
    "    workflow.add_node(\"billing_agent\", billing_agent)\n",
    "    workflow.add_node(\"product_agent\", response_generator)  # Reuse for product queries\n",
    "    workflow.add_node(\"general_agent\", response_generator)\n",
    "    \n",
    "    workflow.set_entry_point(\"intent_router\")\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"intent_router\",\n",
    "        route_to_specialist,\n",
    "        {\n",
    "            \"tech_agent\": \"tech_agent\",\n",
    "            \"billing_agent\": \"billing_agent\",\n",
    "            \"product_agent\": \"product_agent\",\n",
    "            \"general_agent\": \"general_agent\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d62870-af67-4a1a-bf4b-04684906e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any\n",
    "\n",
    "def robust_node_wrapper(func):\n",
    "    \"\"\"Decorator to add error handling to graph nodes.\"\"\"\n",
    "    def wrapper(state: ConversationState) -> ConversationState:\n",
    "        try:\n",
    "            return func(state)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "            \n",
    "            # Add error message to conversation\n",
    "            state[\"messages\"].append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"I encountered an issue. Let me try a different approach.\"\n",
    "            })\n",
    "            \n",
    "            # Set flag for human review\n",
    "            state[\"requires_human_review\"] = True\n",
    "            return state\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "@robust_node_wrapper\n",
    "def safe_response_generator(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"Error-resistant response generation.\"\"\"\n",
    "    return response_generator(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debf512c-78d8-45fe-ae64-99a8957da488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import asyncio\n",
    "\n",
    "class OptimizedChatbot:\n",
    "    def __init__(self):\n",
    "        self.llm_cache = {}\n",
    "        self.response_cache = {}\n",
    "    \n",
    "    @lru_cache(maxsize=1000)\n",
    "    def cached_intent_classification(self, message: str) -> str:\n",
    "        \"\"\"Cache intent classifications for common queries.\"\"\"\n",
    "        # Implementation with caching\n",
    "        pass\n",
    "    \n",
    "    async def async_response_generation(self, state: ConversationState) -> ConversationState:\n",
    "        \"\"\"Asynchronous response generation for better performance.\"\"\"\n",
    "        # Async implementation\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9197ad8-33a2-4583-8cf8-e5f29677ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class ChatbotAnalytics:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"total_conversations\": 0,\n",
    "            \"average_response_time\": 0,\n",
    "            \"escalation_rate\": 0,\n",
    "            \"user_satisfaction\": 0\n",
    "        }\n",
    "    \n",
    "    def track_conversation(self, state: ConversationState, start_time: float):\n",
    "        \"\"\"Track conversation metrics.\"\"\"\n",
    "        response_time = time.time() - start_time\n",
    "        \n",
    "        self.metrics[\"total_conversations\"] += 1\n",
    "        self.metrics[\"average_response_time\"] = (\n",
    "            (self.metrics[\"average_response_time\"] * (self.metrics[\"total_conversations\"] - 1) + response_time) \n",
    "            / self.metrics[\"total_conversations\"]\n",
    "        )\n",
    "        \n",
    "        if state.get(\"requires_human_review\"):\n",
    "            self.metrics[\"escalation_rate\"] += 1\n",
    "    \n",
    "    def log_interaction(self, state: ConversationState):\n",
    "        \"\"\"Log interaction for analysis.\"\"\"\n",
    "        log_entry = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"intent\": state.get(\"current_task\"),\n",
    "            \"messages_count\": len(state[\"messages\"]),\n",
    "            \"escalated\": state.get(\"requires_human_review\", False)\n",
    "        }\n",
    "        \n",
    "        # Send to logging system\n",
    "        logging.info(f\"Interaction logged: {log_entry}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07e235ef-151a-43f3-b251-3b6ec8a61de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "chatbot_graph = create_chatbot_graph()\n",
    "class ChatRequest(BaseModel):\n",
    "    message: str\n",
    "    user_id: str\n",
    "    session_id: str\n",
    "class ChatResponse(BaseModel):\n",
    "    response: str\n",
    "    requires_human: bool\n",
    "    session_id: str\n",
    "@app.post(\"/chat\", response_model=ChatResponse)\n",
    "async def chat_endpoint(request: ChatRequest):\n",
    "    \"\"\"API endpoint for chatbot interactions.\"\"\"\n",
    "    try:\n",
    "        initial_state = {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": request.message}],\n",
    "            \"user_profile\": {},\n",
    "            \"current_task\": None,\n",
    "            \"context_memory\": {},\n",
    "            \"requires_human_review\": False,\n",
    "            \"user_id\": request.user_id\n",
    "        }\n",
    "        \n",
    "        result = chatbot_graph.invoke(initial_state)\n",
    "        \n",
    "        return ChatResponse(\n",
    "            response=result[\"messages\"][-1][\"content\"],\n",
    "            requires_human=result[\"requires_human_review\"],\n",
    "            session_id=request.session_id\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be75ff2-8b5f-4c58-8be8-13a8e63c658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from typing import Dict, Any\n",
    "\n",
    "class ConversationDatabase:\n",
    "    def __init__(self, db_path: str):\n",
    "        self.db_path = db_path\n",
    "        self.init_database()\n",
    "    \n",
    "    def init_database(self):\n",
    "        \"\"\"Initialize database schema.\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS conversations (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                user_id TEXT,\n",
    "                session_id TEXT,\n",
    "                message TEXT,\n",
    "                response TEXT,\n",
    "                intent TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def save_conversation(self, state: ConversationState, session_id: str):\n",
    "        \"\"\"Save conversation to database.\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        last_user_message = None\n",
    "        last_bot_response = None\n",
    "        \n",
    "        for msg in reversed(state[\"messages\"]):\n",
    "            if msg[\"role\"] == \"user\" and not last_user_message:\n",
    "                last_user_message = msg[\"content\"]\n",
    "            elif msg[\"role\"] == \"assistant\" and not last_bot_response:\n",
    "                last_bot_response = msg[\"content\"]\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO conversations (user_id, session_id, message, response, intent)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        \"\"\", (\n",
    "            state.get(\"user_id\", \"anonymous\"),\n",
    "            session_id,\n",
    "            last_user_message,\n",
    "            last_bot_response,\n",
    "            state.get(\"current_task\")\n",
    "        ))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f03d08a-3305-4935-a346-8bb7ebef1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import Mock, patch\n",
    "\n",
    "class TestChatbotComponents(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.sample_state = {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "            \"user_profile\": {},\n",
    "            \"current_task\": None,\n",
    "            \"context_memory\": {},\n",
    "            \"requires_human_review\": False\n",
    "        }\n",
    "    \n",
    "    def test_intent_classification(self):\n",
    "        \"\"\"Test intent classification accuracy.\"\"\"\n",
    "        with patch('langchain_openai.ChatOpenAI') as mock_llm:\n",
    "            mock_llm.return_value.invoke.return_value.content = \"question\"\n",
    "            \n",
    "            result = intent_classifier(self.sample_state)\n",
    "            self.assertEqual(result[\"current_task\"], \"question\")\n",
    "    \n",
    "    def test_escalation_logic(self):\n",
    "        \"\"\"Test escalation decision logic.\"\"\"\n",
    "        self.sample_state[\"current_task\"] = \"complaint\"\n",
    "        result = should_escalate(self.sample_state)\n",
    "        self.assertEqual(result, \"human_agent\")\n",
    "    \n",
    "    def test_response_generation(self):\n",
    "        \"\"\"Test response generation.\"\"\"\n",
    "        with patch('langchain_openai.ChatOpenAI') as mock_llm:\n",
    "            mock_llm.return_value.invoke.return_value.content = \"Test response\"\n",
    "            \n",
    "            result = response_generator(self.sample_state)\n",
    "            self.assertEqual(len(result[\"messages\"]), 2)\n",
    "            self.assertEqual(result[\"messages\"][-1][\"role\"], \"assistant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1bc09a7-6c51-4fca-a84f-3ae6a4663ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_full_conversation_flow():\n",
    "    \"\"\"Test complete conversation flow.\"\"\"\n",
    "    chatbot = create_chatbot_graph()\n",
    "    \n",
    "    test_cases = [\n",
    "        {\n",
    "            \"input\": \"I have a billing question\",\n",
    "            \"expected_intent\": \"billing_inquiry\",\n",
    "            \"should_escalate\": True\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"What are your business hours?\",\n",
    "            \"expected_intent\": \"general\",\n",
    "            \"should_escalate\": False\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for case in test_cases:\n",
    "        initial_state = {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": case[\"input\"]}],\n",
    "            \"user_profile\": {},\n",
    "            \"current_task\": None,\n",
    "            \"context_memory\": {},\n",
    "            \"requires_human_review\": False\n",
    "        }\n",
    "        \n",
    "        result = chatbot.invoke(initial_state)\n",
    "        \n",
    "        # Verify expected behavior\n",
    "        assert result[\"current_task\"] == case[\"expected_intent\"]\n",
    "        assert result[\"requires_human_review\"] == case[\"should_escalate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd241f5f-152b-4bb4-8f49-06e9720b6f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "langgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
