# Awesome-AIGC

[![Anurag's GitHub stats](https://github-readme-stats.vercel.app/api?username=wshzd)](https://github.com/anuraghazra/github-readme-stats)

自2022年11月份OpenAI公布ChatGPT以来，ChatGPT在五天之内注册用户数就突破了百万

![ChatGPT](images/chatgpt.png)

由此拉开了AIGC大模型的序幕，也有人称为是AI2.0时代，2023年3月14日又发布了GPT4，性能进一步得到提升，关于ChatGPT和GPT4为代码的文本生成以及Codex的代码生成等博客和论文层出不穷，这里对一些重点资料进行了整理归类，持续更新中......

## 技术交流

欢迎加入AIGC技术交流群，与AI领域专家和各行各业的AIGC爱好者一起交流技术理论与行业信息！不管你是学术界还是工业界实践者或爱好者，都欢迎加入群体！

| 交流群二维码                    | 拉你入群(备注AIGC-github)  |
| ------------------------------- | :------------------------: |
| ![Arron](images/AIGC_group.jpg) | ![Arron](images/Arron.jpg) |

## AIGC视频会议&访谈

### 智源社区

**【论文分享】**【AugGPT：利用ChatGPT进行文本数据增强 】[[link](https://event.baai.ac.cn/activities/664 )]

**【论文分享】**【ChatGPT的鲁棒性探究——对抗性和分布外泛化的视角 】[[link](https://event.baai.ac.cn/activities/657 )]

**【论文分享】**【传统检索模型和大语言模型在信息搜索中的应用和对比 】[[link](https://event.baai.ac.cn/activities/656 )]，[[paper](https://arxiv.org/abs/2209.10063)]，[[code](https://github.com/wyu97/GenRead )]，[[blog](https://hub.baai.ac.cn/view/24380 )]

### 访谈&视频

**【访谈】**【OpenAI 的核心研发人员 Jack Rae 在参加 Stanford MLSys Seminar 的访谈时进行了一个名为 Compression for AGI的主题分享 】[[访谈记录](https://mp.weixin.qq.com/s/hQmvltuMlClBonM6UJmtLg)]

**【访谈】**【万字长文：想训大模型？这里有一份避坑指南】[[访谈记录](https://mp.weixin.qq.com/s/yX5B1ZzV7vewQs1-ezHIQg)]

**【访谈】**【微软Bing版ChatGPT表明想做人类，并且对纽约时报专栏作家表达爱意】[[访谈记录](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485854&idx=1&sn=011e0ef0f2c69cd48d042495b2a47eb3&chksm=ced54a7af9a2c36c29fec6301236685d443bde94681ec3f669408d953ae92bb54b686aeab9f8&token=447941009&lang=zh_CN#rd)]

**【访谈】**【Midjourney创始人David Holz关于生成式AI的访谈】[[访谈记录](https://mp.weixin.qq.com/s/jMyuSYu8ACk2peu_OfZK0w)]

**【访谈】**【OpenAI创始人：GPT-4的研究起源和构建心法】[[访谈记录](https://mp.weixin.qq.com/s/hO1ZdqgOjpA328luobQ9eg)]

**【访谈】**【ABC News 专访OpenAI首席执行官萨姆·奥尔特曼：AI风险和重塑社会的问题】[[访谈记录]([OpenAI CEO Sam Altman says AI will reshape society, acknowledges risks: 'A little bit scared of this](https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122) )]

**【访谈】**【OpenAI联合创始人Ilya Sutskever等专访：开源人工智能是不明智的】[[访谈记录](https://www.theverge.com/2023/3/15/23640180/openai-gpt-4-launch-closed-research-ilya-sutskever-interview )]

**【访谈】**【OpenAI董事长、CTO Greg Brockman专访 ：GPT-4 并不完美，不过人无完人】[[访谈记录](https://techcrunch.com/2023/03/15/interview-with-openais-greg-brockman-gpt-4-isnt-perfect-but-neither-are-you/ )]

**【访谈】**【图灵奖获得者 Yoshua Bengio 认为 ChatGPT 是一个“警钟”】[[访谈记录](https://mp.weixin.qq.com/s/2-QoJHKWxiS63vEjX9OOGQ)]

**【访谈】**【《麻省理工科技评论》对 ChatGPT 幕后团队，进行了一次深入的独家专访】[[访谈记录](https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai )]

**【访谈】**【口述历史，探析ChatGPT的创造历程，ChatGPT内部故事】[[访谈记录](https://mp.weixin.qq.com/s/RAdIxzdgs3elUiozB8cH8g)]

**【访谈】**【对话ChatGPT之父！AI会改变什么？不会改变什么？】[[访谈记录](https://mp.weixin.qq.com/s/zNuOmVeVKP335iJ4RNJqNw)]

**【访谈】**【对话OpenAI研究科学家：他们是如何让GPT4更像人的？】[[访谈记录](https://mp.weixin.qq.com/s/iJImioHXxelCxUsETSxuXw)]

**【视频】**【邱锡鹏教授介绍以ChatGPT为核心的大规模语言模型的相关知识及未来的发展方向 】[[B站](https://www.bilibili.com/video/BV1Xb411X7c3/)]

## 中国版ChatGPT

无需注册即可体验ChatGPT效果的一些网站

http://chat.h2ai.cn/home

https://chat.forchange.cn/

https://aigcfun.com/

https://xc.com/

## LLM体验效果&专业评估

**【LLM效果对比】**【Bard_VS_Baize-7B_VS_文心一言】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247486317&idx=1&sn=ea3cc745d2991b8c657325392ce68f71&chksm=ced54889f9a2c19f3c2f85d8d7af7fff366027f79d1f4a5b2c650fea1b5dee9efde0b7c992ca&token=1173964254&lang=zh_CN#rd)]

**【LLM效果对比】**【Bard_VS_Bing_VS_ChatGPT】[[blog](https://www.theverge.com/2023/3/24/23653377/ai-chatbots-comparison-bard-bing-chatgpt-gpt-4)]

**【LLM效果对比】**【Bard_VS_文心一言】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247486260&idx=1&sn=a41224fee7ed4cb4a48eb40a420d7479&chksm=ced548d0f9a2c1c6f4930f30447468f9f01bb2af6031368e302b13a6354fc4bca6636e3b297e&token=666852558&lang=zh_CN#rd)]

**【LLM效果对比】**【文心一言新闻发布会内容复现】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247486081&idx=1&sn=034480a8b00778cb6a4f2b5ea4214974&chksm=ced54965f9a2c0733ff09fbff4953da484180f48545da3d9b476f1e7375c162f9e8d4eaa0afd&token=666852558&lang=zh_CN#rd)]

**【LLM效果对比】**【文心一言_VS_ChatGLM-6B】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247486081&idx=2&sn=fd87305419158d66dd4b05b57bee1324&chksm=ced54965f9a2c073ba1badfedbc6610036455cd769a3c8ee3445f7fbff9364b5624091be9914&token=666852558&lang=zh_CN#rd)]

**【LLM效果对比】**【文心一言 VS GPT-4：20道问答PK】[[blog](https://mp.weixin.qq.com/s/l1pTPlohMmiYEMc4x6QKhw)]

**【LLM效果对比】**【文心一言 vs GPT-4实测！】[[blog](https://mp.weixin.qq.com/s/uO8N3RpcrYU8rV1RkwBxzQ)]

**【LLM效果对比】**【ChatGPT_VS_GPT4】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485952&idx=2&sn=e54a62e358bf7aee3c007d59600fd452&chksm=ced549e4f9a2c0f2868eb8877c14fbe287a469e63b09774cefcb9edc4c0601016f6d36561973&token=666852558&lang=zh_CN#rd)]

**【ChatGPT专业评估】**【一文看遍各行业对ChatGPT的专业评估】[[blog](https://mp.weixin.qq.com/s/2JryWW33j9udOpi3dK5X9g)]

**【ChatGPT专业评估】**【ChatGPT关于推理、幻觉和交互的多任务、多语言、多通道评估 】[[paper](https://arxiv.org/abs/2302.04023 )]

**【ChatGPT专业评估】**【如何评价 OpenAI 的超级对话模型 ChatGPT ？】[[paper](https://www.zhihu.com/question/570189639)]

**【ChatGPT专业评估】**【用ChatGPT参加计算机科学考试】[[paper](https://arxiv.org/abs/2303.09461 )]

## LLM文本检测

**【论文&代码】**【美国麻省大学&谷歌研究院：改写文本可以避开AI生成文本的检测器，但检索则是一种有效的防御】[[paper](https://papers.labml.ai/api/v1/redirect/pdf?paper_key=2cfe8cecc9f211edb95839eec3084ddd )]，[[code](https://github.com/martiansideofthemoon/ai-detection-paraphrases )]

**【论文】**【人工智能生成的文本能被可靠地检测出来吗？】[[paper](https://arxiv.org/pdf/2303.11156.pdf )]，[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247486128&idx=3&sn=e5ea32b7d7cb4c8c41f29a9ea15ac3ac&chksm=ced54954f9a2c0425a65761f1766550f6b90857da0106f6fd55f3c6773fbdbd1fc45bbb9369a&token=447941009&lang=zh_CN#rd)]

**【论文】**【DetectGPT（斯坦福大学）：利用概率曲率检测文本是否大模型生成】[[paper](https://arxiv.org/abs/2301.11305 )]，[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485713&idx=2&sn=805caf25603cf15dbf71949f85b9d041&chksm=ced54af5f9a2c3e3e0dffd728592fd7ab8f738869e94240daba4fad9f6ac90a2f76a6b458e3f&token=447941009&lang=zh_CN#rd)]，[[code&data](https://ericmitchell.ai/detectgpt/ )]

**【论文】**【Detecting LLM-Generated-Text综述】[[paper](https://github.com/datamllab/The-Science-of-LLM-generated-Text-Detection)]，[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485747&idx=1&sn=5e5029a70c54c08f6f8c40631962b1e1&chksm=ced54ad7f9a2c3c184ccb123199510bb09470e054fb5cb887e70bac204927b65e296f8921db1&token=447941009&lang=zh_CN#rd)]

**【论文】**【一个专为**教育**者打造的全新 AI 检测模型】[[blog](https://gptzero.substack.com/p/gptzerox )]

**【论文】**【OpenAI重磅发布官方「ChatGPT检测器」】[[blog](https://mp.weixin.qq.com/s/EcZE7TgHspf22rPRWhAybw)]

**【论文】**【斯坦福最新研究：不要过度依赖GPT生成内容，其检测器可能存在不利于非母语英语写作者的偏见】[[paper](https://arxiv.org/abs/2304.02819)]

## LLM博客、论文以及代码

**【复旦大学】**【复旦大学教授肖仰华：ChatGPT 浪潮下，面向大模型如何做数据治理？】[[blog](https://mp.weixin.qq.com/s/od24PYvFLUJe4NQxjvsbMw)]

**【谷歌】**【面向决策的基础模型: 问题、方法与机会】[[paper](https://arxiv.org/abs/2303.04129)]

**【谷歌】**【较大语言模型上下文学习的方式有所不同】[[paper](https://arxiv.org/abs/2303.03846)]

**【谷歌】**【通用语音识别大模型已经支持100+语言】[[blog](https://mp.weixin.qq.com/s/fHr2vL-w4JtYt5utcZrbsw)]

**【谷歌】**【发布5620亿参数多模态模型PaLM-E，机器人操控再上台阶】[[paper](https://arxiv.org/abs/2303.03378 )]，[[blog](https://palm-e.github.io/ )]，[[twitter](https://twitter.com/DannyDriess/status/1632904675124035585 )]，[[video](https://mp.weixin.qq.com/s/yZt3sEQPzVjnIvqXsNOnPA )]

**【Huawei】**【PanGu-Σ: 稀疏异构计算万亿参数语言模型研究参数语言模型】[[paper](https://arxiv.org/abs/2303.10845 )]

**【剑桥大学】**【奖励聊天机器人在现实世界中与数以百万计的用户进行互动】[[paper](https://arxiv.org/pdf/2303.06135.pdf )]

**【LeCun】**【人工智能系统最终是否需要以现实为基础，而不仅仅是从语言中学习？】[[blog](https://spectrum.ieee.org/ai-hallucination )]

**【LeCun】**【大型语言模型是否需要感官基础来理解意义和理解？】[[slices](https://drive.google.com/file/d/1BU5bV3X5w65DwSMapKcsr0ZvrMRU_Nbi/view )]

**【LeCun】**【ChatGPT是「外星人」，所以才会胡说八道】[[paper](https://www.noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial)]，[[blog](https://twitter.com/ylecun/status/1633459264508542978 )]

**【LeCun】**【AI聊天机器人并不关注用户的社交属性】[[blog](https://www.noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial)]

**【LeCun】**【LeCun和马库斯齐喷ChatGPT：大语言模型果然是邪路？】[[blog](https://mp.weixin.qq.com/s/5e0aTSEAym9rF5QxRndLgQ)]

**【LeCun】**【ChatGPT无法实现通用人工智能，但ALM技术路线也许可以】[[blog](https://mp.weixin.qq.com/s/MEdl3zmiYJU1iFsTXmibng)]

**【LeCun】**【「增强语言模型」的综述 】[[paper](https://arxiv.org/abs/2302.07842 )]

**【LeCun】**【自回归LLM的缺陷之一，大语言模型必须知道的8个要点】[[paper](https://cims.nyu.edu/~sbowman/eightthings.pdf)]

**【李开复】**【AI进入2.0时代，所有应用都会被重写一遍 】[[blog](https://mp.weixin.qq.com/s/zV8Y9RQnIoExwa1mmarZmA)]

**【纽约大学】**【提出ILF（从语言反馈中模仿学习）：利用语言反馈大规模训练语言模型】[[paper](https://arxiv.org/pdf/2303.16755.pdf )]

**【OpenAI】**【GPT就是GPT：大模型对劳动力市场影响潜力的早期研究】[[paper](https://arxiv.org/pdf/2303.10130.pdf )]

**【OpenAI】**【ABC News 专访OpenAI首席执行官萨姆·奥尔特曼：AI风险和重塑社会的问题】[[blog](https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122)]

**【OpenAI】**【最新发布通用人工智能路线图！AGI比想象中来得更快！】[[blog](https://openai.com/blog/planning-for-agi-and-beyond/)]

**【OpenAI】**【Sam Altman 担心“潜在的可怕的”人工智能工具以及“未来的人们如何看待我们” 】[[blog](https://finance.yahoo.com/news/openai-ceo-sam-altman-frets-165250285.html)]

**【OpenAI】**【The Age of AI：拾象大模型及OpenAI投资思考】[[blog](https://mp.weixin.qq.com/s/AxX-Q7njegNTAxMkYFwsfA)]

**【PWC】**【ChatGPT和生成式AI的11大安全趋势】[[blog](https://mp.weixin.qq.com/s/_RAx3vAx1ykQTJTEEoc37w)]

**【人大】**【人大最新大语言模型综述，51页全面回顾大语言模型】[[paper](https://arxiv.org/pdf/2303.18223.pdf)]

**【清华大学】**【张学工教授：AI技术前沿——从ChatGPT到更多突破】[[blog](https://mp.weixin.qq.com/s/oeZd52BYKU3hhauZZ0eirQ)]

**【斯坦福】**【研究大语言模型反映了谁的观点？】[[paper](https://arxiv.org/pdf/2303.17548.pdf)]，[[code](https://github.com/tatsu-lab/opinions_qa )]

**【斯坦福】**【大模型及其公平使用】[[paper](https://arxiv.org/pdf/2303.15715.pdf )]

**【斯坦福】**【构建大模型生态系统图，用于跟踪大模型的足迹】[[blog](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=home)]

**【斯坦福】**【斯坦福报告：基础模型的机遇与风险】[[blog](https://mp.weixin.qq.com/s/iEwvkqMT7KEqmnHk8NVz6w)]

**【微软】**【一种新的大语言模型NLG评估框架】[[paper](https://arxiv.org/abs/2303.16634 )]

**【微软 & Meta】**【ART：大型语言模型的自动多步骤推理和工具使用】[[paper](https://arxiv.org/pdf/2303.09014.pdf)]

**【EleutherAI&耶鲁大学】**【提出Pythia： 跨越训练和扩展的大型语言模型分析套件】[[paper](https://arxiv.org/pdf/2304.01373.pdf )]，[[code](https://github.com/EleutherAI/pythia )]

**【博客】**【NAACL & ACL：大模型的两种知识继承方案】[[方案一](https://aclanthology.org/2022.naacl-main.288/)]，[[方案二](https://aclanthology.org/2022.acl-long.151/)]

**【博客】**【LLM，压缩即泛化，泛化即智能】[[blog](https://mp.weixin.qq.com/s/tSj9npIPg8IlYr2jbtg-Og)]

**【博客】**【智慧信息的压缩：模型智能的涌现之道】[[blog](https://mp.weixin.qq.com/s/hQmvltuMlClBonM6UJmtLg)]

**【博客】**【拨动大模型的琴弦｜Delta Tuning 成果登上 Nature子刊封面！】[[blog](https://mp.weixin.qq.com/s/m3fNselWKQ2m5XnBe79fQQ)]

**【博客】**【大型人工智能模型中出现的不可预测的能力】[[blog]([https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/ ](https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316) )]

**【博客】**【为什么现在的大语言模型（LLM）都是Decoder-only的架构？】[[blog](https://mp.weixin.qq.com/s/ZsHX-M9pisUvG9vqfzdzTQ)]

**【博客】**【大型语言模型的涌现能力】[[blog](https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/)]

**【博客】**【大型语言模型成本分析】[[blog](https://hub.baai.ac.cn/view/24047)]

**【博客】**【超越ChatGPT：大模型的智能极限 】[[blog](https://yaofu.notion.site/e1cd16d1fae84f87aeddf872c838e07c)]

**【博客】**【Nature：AI模型越大越好吗? 】[[blog](https://www.nature.com/articles/d41586-023-00641-w)]

**【博客】**【一场关于ChatGPT话语权的深度思考：人类会在大模型中迷失自我吗？】[[blog](https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html)]，[[blog译文](https://mp.weixin.qq.com/s/RPiIh5cbxzXl5uMo_BVFMg)]

**【博客】**【马斯克强调的TruthGPT 是什么】[[blog](https://mp.weixin.qq.com/s/_nSYK63DvqE7ZJyJz6NeEA)]

**【博客】**【对话式AI搜索的技术路线猜想】[[blog](https://mp.weixin.qq.com/s/AIIu4rRi1WZRQn3oHtuwdg)]

**【博客】**【AI走过多少路，才迎来了ChatGPT？】[[blog](https://mp.weixin.qq.com/s/WWc39HtuV-TrbwFybX112Q)]

**【博客】**【如何负责任地创建、发布和共享生成式 AI】[[blog](https://www.technologyreview.com/2023/02/27/1069166/how-to-create-release-and-share-generative-ai-responsibly/)]

**【博客】**【大模型时代的“Linux”生态，开启人工智能新十年】[[blog](https://mp.weixin.qq.com/s/sUmA3nSSVfNQFBgSjiSn0g)]

**【博客】**【PEFT: 在低资源硬件上对十亿规模模型进行参数高效微调 】[[blog](https://hub.baai.ac.cn/view/24622)]

**【博客】**【揭秘ChatGPT背后的AI“梦之队”：90后科研“后浪”展示强大创新能力｜智谱研究报告】[[blog](https://mp.weixin.qq.com/s/sncE01utzu_-r3dLFYU5QA)]

**【博客】**【In-Context Learning玩法大全 】[[blog](https://mp.weixin.qq.com/s/sC3Xq1QQmtC8Tz84oRRwcw)]

**【博客】**【一文理解“上下文学习”----大语言模型突现能力】[[blog](https://mp.weixin.qq.com/s/0kchPu20nwCKCXk4PZBkOg)]

**【论文】**【大模型微调指南：当GPU资源不足时的有效解决方案】[[paper](https://arxiv.org/pdf/2303.15647.pdf )]

**【论文】**【**TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs** 】[[paper](https://arxiv.org/pdf/2303.16434.pdf )]

**【论文】**【**AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators** 】[[paper](https://arxiv.org/pdf/2303.16854.pdf )]

**【论文】**【南加州大学:大语言模型统计偏好的挑战和危险 】[[paper](https://arxiv.org/pdf/2304.03738.pdf)]

**【论文】**【卡内基·梅隆大学 | 语言生成模型可能造成危害：那么我们能做些什么呢？】[[paper](https://arxiv.org/pdf/2210.07700.pdf)]

**【论文】**【鹏程实验室等最新《大规模多模态预训练模型》全面综述 】[[paper](https://arxiv.org/abs/2302.10035)]

**【论文】**【预训练基础模型综合调研：从 BERT 到 ChatGPT 的历史 】[[paper](https://arxiv.org/abs/2302.09419 )]

**【论文】**【洛桑联邦理工学院提出REFINER框架，用于微调大规模语言模型】[[paper](https://arxiv.org/pdf/2304.01904.pdf )]

**【论文】**【LLM-Adapters： 用于大型语言模型的参数高效微调的适配器系列】[[paper](https://arxiv.org/pdf/2304.01933.pdf )]

**【综述】**【大型语言模型综述全新出炉：从T5到GPT-4最全盘点，国内20余位研究者联合撰写】[[paper](https://arxiv.org/abs/2303.18223)]

**【综述】**【AIGC综述: 从GAN到ChatGPT的生成式人工智能简史 】[[paper](https://arxiv.org/abs/2303.04226v1 )]

**【论文】**【机器心理学：使用心理学方法研究大型语言模型中的涌现能力和行为】[[paper](https://arxiv.org/abs/2303.13988v1)]

**【代码】**【大型语言模型相关文献资源列表】[[code](https://github.com/RUCAIBox/LLMSurvey)]

## Prompt工程

**【博客】**【OpenAI 应用人工智能研究负责人Lilian Weng新博文：关于提示工程的介绍】[[blog](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)]

**【博客】**【Prompt Engineering全面自动化】[[blog](https://mp.weixin.qq.com/s/aj8Ls463jpF92ssn6Acwzg)]

**【博客】**【ChatGPT提示示例集合】[[地址](https://prompts.chat)]，[[code](https://github.com/f/awesome-chatgpt-prompts/)]，[huggingface](https://huggingface.co/datasets/fka/awesome-chatgpt-prompts )]

**【博客】**【深入浅出Prompt Learning要旨及常用方法】[[blog](https://mp.weixin.qq.com/s/Wgj1ATMAkL1Gx4dsAlkJZw )]

**【博客】**【ChatGPT火爆，最全prompt工程指南登GitHub热榜，标星4.7k！】[[code](https://github.com/dair-ai/Prompt-Engineering-Guide)]，[youtube](https://www.youtube.com/watch?v=dOxUroR57xs)]

**【博客】**【ChatGPT Prompt工程：设计、实践与思考】[[blog](https://mp.weixin.qq.com/s/a8hjzZ_Rzl6pOU1PRAARJQ)]

**【博客】**【全面的提示工程指南】[[blog](https://www.promptingguide.ai/zh)]

**【博客】**【指令学习综述｜ChatGPT背后的指令学习是什么】[[blog](https://mp.weixin.qq.com/s/BK30JkIlshwkdHRjaRCD2g)]，[[paper](https://arxiv.org/pdf/2303.10475v2.pdf)]

## AGI开源工具&博客&论文

**【工具】**【Google发布统计深度学习框架平台：OpenXLA】[[blog](https://github.com/wshzd/ChatGPT-Summary/blob/main/AGI/Google_OpenXLA.md)]

**【博客】**【AGI的火花一作Sébastien Bubeck演讲万字全文】[[blog](https://mp.weixin.qq.com/s/H1RVdH0fmwM0GjfV3uvd4g)]

**【论文】**【OpenAGI:当大语言模型遇到领域专家】[[paper](https://arxiv.org/abs/2304.04370)]，[[code](https://github.com/agiresearch/OpenAGI )]

## 文本生成

### ChatGPT

从GPT3到ChatGPT模型的发展路线图

![ChatGPT_family](images/chatgpt-3.jpg)

#### ChatGPT 应用篇

**【58】**【从 GPT 到 ChatGPT 的演进与应用思考】[[blog](https://mp.weixin.qq.com/s/3Pr82xKpZ7mAWQcxPPB1xA)]

**【MIT & 哈佛大学 】**【语言模型可以预测公众舆论 】[[paper](https://arxiv.org/pdf/2303.16779.pdf )]

**【中科院】**【ChatGPT助力芯片，传统 EDA如何演变成智能EDA】[[blog](https://mp.weixin.qq.com/s/JyveUDEYKLrFolfCFLqhhw)]

**【微软】**【《ChatGPT机器人:设计原则和模型能力》论文 】[[paper](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/)]

**【微软】**【各种环境下的ChatGPT赋能长步机器人控制： 一个案例的应用 】[[paper](https://arxiv.org/pdf/2304.03893.pdf )]，[[code](https://github.com/microsoft/ChatGPT-Robot-Manipulation-Prompts )]

**【博客】**【ChatGPT获得了「Wolfram」超能力】[[blog](https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/)]

**【博客】**【OpenAI开发Plugin将 ChatGPT 连接到互联网】[[blog](https://techcrunch.com/2023/03/23/openai-connects-chatgpt-to-the-internet/ )]

**【博客】**【ChatAug：利用ChatGPT进行文本数据增强】[[paper](https://arxiv.org/abs/2302.13007 )]

**【博客】**【ChatGPT 是数据隐私的另一个障碍吗】[[blog](https://www.bizcommunity.com/Article/196/639/236418.html)]

**【博客】**【基于ChatGPT的数据增强方法：ChatAug和AugGPT】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247486140&idx=1&sn=bba4342966c99559938824f2d747d231&chksm=ced54958f9a2c04ec121b8c198d69a5a17c8b3e0a96a0cfcd8d1271bd6097a2cbf66895dd8a9&token=447941009&lang=zh_CN#rd)]

**【博客】**【Character.AI 在ChatGPT基础上加入个性化、UGC两大武器，有比 ChatGPT 更丰富的使用场景】[[blog](https://mp.weixin.qq.com/s/U4R8loz1G9PYM_l6IvNF_A )]

**【博客】**【让ChatGPT可以**语音交互**】[[blog](https://mp.weixin.qq.com/s/H4XLCQ-kR7T28yywHJL4uA)]

**【博客】**【“ChatGPT们”的淘金时代】[[blog](https://mp.weixin.qq.com/s/otdenJh5FJsCgi5ONy9JIQ)]

**【论文】**【人大提出WebBrain：NLP新任务，通过网络数据的挖掘生成真实文章】[[paper](https://arxiv.org/abs/2304.04358)]，[[code](https://github.com/qhjqhj00/WebBrain )]

**【医疗】**【ChatGPT爆火带来思考：医学界或将迎来与AI融合的奇点？】[[blog](https://mp.weixin.qq.com/s/x8ppg6GVCAeLNpv5uJ7B7g )]

**【教育】**【论ChatGPT大语言模型在教育中的机遇与挑战 】[[blog](https://url39.ctfile.com/f/2501739-809898048-6394c7?p=2096 )]

**【投资】**【ChatGPT在投资研究领域的应用初探及原理分析】[[blog](https://mp.weixin.qq.com/s/LFPeSLeEOTb1-2YJBXclbQ)]

**【软件】**【OpenAI总裁Greg Brockman转发｜一种编译语言的调试器，利用ChatGPT旨在增强您使用GDB进行调试体验】[[code](https://github.com/pgosar/ChatGDB)]

**【软件】**【不必排队等 OpenAI Plugins，OpenBMB 开源大模型工具学习引擎】[[blog](https://hub.baai.ac.cn/view/25189)]

**【其他】**【分析了ChatGPT技术以及落地应用场景 】[[blog](https://url39.ctfile.com/f/2501739-805099789-098b62?p=2096)]

#### ChatGPT 工具篇

**【工具】**【ChatGPT 应用汇总及操作手册】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485794&idx=1&sn=6aa0500e3139b67246dd5f96007d1487&chksm=ced54a86f9a2c390d86856181f1fcd09091cf84d67e81535b6d592617f49fe24349779cfa1e5&token=447941009&lang=zh_CN#rd)]

**【工具】**【ChatGPT提示和技巧速查手册】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485766&idx=1&sn=43ad627e4e183d7a108c3c57ab0e02dc&chksm=ced54aa2f9a2c3b4a2d529e4ed7c2acc7fa32e7465837045d3ec607701e0da2a55c0c557cad2&token=447941009&lang=zh_CN#rd)]

**【工具】**【非常全面的ChatGPT、LLM相关资源整理分享】[[code](https://github.com/cedrickchee/chatgpt-universe)]

**【工具】**【ChatGPT超全面课程】[[blog](https://tested-salto-cab.notion.site/The-Ultimate-Chat-GPT-Course-69ed24a317a942d288e740419b1ad6f6 )]

**【工具】**【BloombergGPT: A Large Language Model for Finance】[[paper](https://papers.labml.ai/api/v1/redirect/pdf?paper_key=b0e4b03ecf5c11edb95839eec3084ddd)]

**【工具】**【ChatPDF：一键上传PDF文件即可解读 】[[blog](https://mp.weixin.qq.com/s/S1DUJrNK5_H5krvHotOwHQ)]，[[试用地址](https://www.chatpdf.com/ )]

**【工具】**【Einstein GPT：SaaS 行业巨头 Salesforce 宣布与 OpenAI 合作，推出 Einstein GPT，这是全球首个用于客户关系管理（CRM）的生成式 AI 产品 】[[Einstein GPT地址](https://www.salesforce.com/products/einstein/overview/?d=cta-body-promo-8 )]，[[试用地址](https://openai.com/waitlist/slack )]

**【工具】**【HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace 】[[paper](https://arxiv.org/pdf/2303.17580.pdf )]

**【工具】**【Visual ChatGPT: 在视觉模型加持下的ChatGPT，聊天生图全拿捏了。】[[paper](https://arxiv.org/pdf/2303.04671.pdf )]

**【工具】**【ChatWeb：可爬取网页正文，并根据正文回答问题 】[[code](https://github.com/SkywalkerDarren/chatWeb )]

**【工具】**【OpenGpt：创建ChatGPT小应用的AI平台】[[官网](https://open-gpt.app/)]，[[code](https://github.com/futantan/OpenGpt )]

**【工具】**【TagGPT：腾讯提出零样本多模态标签的大语言模型TagGPT】[[paper](https://arxiv.org/abs/2304.03022)]，[[code](https://github.com/TencentARC/TagGPT )]

**【工具】**【chatgpt_academic：中科院基于 ChatGPT 专属定制的学术研究及日常开发工具】[[blog](https://hub.baai.ac.cn/view/25298)]，[[code](https://github.com/binary-husky/chatgpt_academic)]，[[demo](https://huggingface.co/spaces/qingxu98/gpt-academic)]

#### ChatGPT 技术篇

**【符尧】**【深度拆解GPT-3.5能力起源】[[原文blog](https://yaofu.notion.site/GPT-3-5-360081d91ec245f29029d37b54573756)]，[[译文blog](https://mp.weixin.qq.com/s/ckd6KxeTfdQas_UCsJ7HgQ)]

**【知乎】**【ChatGPT发展历程、原理、技术架构详解和产业未来】[[blog](https://zhuanlan.zhihu.com/p/590655677 )]

**【斯坦福】**【82页PPT ！最新ChatGPT: 提示学习, 指导微调和RLHF 】[[blog](https://pan.baidu.com/s/15Bs1u7z1RhCdfiR3oJ_gJQ)]，[提取码:chat]

**【微软】**【让天下没有难训练的大模型，微软亚洲研究院开源TorchScale 】[[code](https://github.com/microsoft/torchscale )]

**【亚马逊 】**【他们提出了包含视觉特征的 Multimodal-CoT，该架构在参数量小于 10 亿的情况下，在 ScienceQA 基准测试中，比 GPT-3.5 高出 16 个百分点 】[[paper](https://arxiv.org/abs/2302.00923 )]，[[code](https://github.com/amazon-science/mm-cot)]

**【OpenBMB】**【Nature ：生成式 AI 的前景与风险】[[blog](https://mp.weixin.qq.com/s/d6t2xpdvSDCHzO2gG1N6eQ)]

**【LoRA】**【LoRA：卷完图像生成领域，卷文本生成领域的东西，到时是个啥？】[[blog](https://mp.weixin.qq.com/s/emLpTAOhr8khO1hTgQhU9w)]，[[code](https://github.com/microsoft/LoRA)]

**【博客】**[ChatGPT_Inference_Cost](https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Inference_Cost.md)

**【博客】**[ChatGPT_Official_API_Learning](https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Official_API_Learning.md)

**【博客】**[ChatGPT_Parameter_is_not_175B](https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Parameter_is_not_175B.md)

**【博客】**[ChatGPT_Road_Map_from_yao.fu](https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/ChatGPT_Road_Map_from_yao.fu.md)

**【博客】**[Lessons_Learned_from_ChatGPT_Recurrence](https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/Lessons_Learned_from_ChatGPT_Recurrence.md)

**【博客】**[LLM_Pre-training_Guide（Bloom-175B）](https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/LLM_Pre-training_Guide（Bloom-175B）.md)

**【博客】**[The_guide_of_training_LLM](https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT/Blog/ChatGPT_Technology/The_guide_of_training_LLM.md)

**【博客】**【AI芯片制造商Cerebras发布7个基于GPT的大语言模型，现已开源】[[官网地址](https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/) )]，[[GPT地址](https://www.cerebras.net/cerebras-gpt  )]，[[Hugging Face地址 ](https://huggingface.co/cerebras  )]

**【博客】**【大模型论文周报丨GPT-4发布，谷歌开放PaLM API，斯坦福7B开源模型Alpaca媲美GPT-3.5】[[blog](https://mp.weixin.qq.com/s/C6g_H6xfFn59IxnLpbjA1g)]

**【博客】**【LLaMA模型Meta版泄露，GitHub获8K星】[[blog](https://mp.weixin.qq.com/s/2M19WSq2YICo-3t5ibQcig)]

**【博客】**【ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction Benchmark 】[[paper](https://arxiv.org/abs/2303.13648 )]

**【博客】**【打造中国版ChatGPT，国内哪家实力最强】[[blog](https://mp.weixin.qq.com/s/B-n_qz110HmhSP66NKRCiQ)]

**【博客】**【复旦大学邱锡鹏教授解读ChatGPT】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485810&idx=1&sn=47eb672c688517d6bade2c62c7eae94f&chksm=ced54a96f9a2c380ccacfbb223df52de64f2c410a91e726023a074fc98fb87fcd9f60f5a4957&token=447941009&lang=zh_CN#rd)]

**【博客】**【万字长文:可能是全网最晚的ChatGPT技术总结 】[[blog](https://mp.weixin.qq.com/s/LJoxupaKflL793TCwnpyPg)]

**【博客】**【ChatGPT作为知识库问答系统的问答能力评测 】[[blog](https://mp.weixin.qq.com/s/xul2-SENnqxV8VehozDKHg )]

**【博客】**【ChatGPT作者John Shulman：我们成功的秘密武器】[[blog](https://www.talkrl.com/episodes/john-schulman)]，[[blog译文](https://mp.weixin.qq.com/s/sDeBYMvAwbJr5_tj7Q20-w )]

**【博客】**【ChatGPT 是数据隐私的另一个障碍吗】[[blog](https://www.bizcommunity.com/Article/196/639/236418.html)]

**【博客】**【Hugging Face 每周速递: ChatGPT API 怎么用？我们帮你搭好页面了 】[[blog](https://mp.weixin.qq.com/s/oeXgd78vFV8os2uTGZkFQQ)]

**【博客】**【复旦大学教授肖仰华：ChatGPT 浪潮下，面向大模型如何做数据治理？】[[blog](https://mp.weixin.qq.com/s/od24PYvFLUJe4NQxjvsbMw)]

**【博客】**【腾讯在ChatGPT的布局】[[blog](https://mp.weixin.qq.com/s/rdpGZII3pu3MHr-lFm3GyQ)]

**【博客】**【浅析ChatGPT：历史沿革、应用现状及前景展望】[[blog](https://mp.weixin.qq.com/s/fQ8DmL_M3QMiFX23Tf0z7w)]

**【博客】**【ChatGPT 背后的“功臣”——人类反馈强化学习RLHF 技术详解】[[blog](https://mp.weixin.qq.com/s/mZdZS9QNda26Ae0OIhRjFA)]

**【博客】**【万字长文解析！复现和使用GPT-3/ChatGPT，你所应该知道的】[[blog](https://mp.weixin.qq.com/s/ILpbRRNP10Ef1z3lb2CqmA)]

**【博客】**【想训练ChatGPT？得先弄明白Reward Model怎么训（附源码） 】[[blog](https://mp.weixin.qq.com/s/1v4Uuc1YAZ9MRr1UWMH9xw)]

**【博客】**【ChatGPT核心技术：强化学习PPO算法】[[blog](https://mp.weixin.qq.com/s/z4oc9xQmduKMolWxztdHjA)]

**【博客】**【解读 ChatGPT 背后的技术重点：RLHF、IFT、CoT、红蓝对抗】[[blog](https://mp.weixin.qq.com/s/y4ywidZ55BQLgQzJa_Wjbg)]

**【伦理】**【加拿大魁北克大学教授详述：我们该拿ChatGPT怎么办？】[[blog](https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/)]

**【论文】**【ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of Commonsense Problem in Large Language Models】[[paper](https://arxiv.org/pdf/2303.16421.pdf )]

**【论文】**【GPT-3 和 GPT-3.5 系列模型的全面分析】[[paper](https://arxiv.org/abs/2303.10420v1)]

**【论文】**【ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks】[[paper](https://arxiv.org/pdf/2303.15056.pdf )]

**【论文】**【微软&佐治亚理工学院 | AdaLoRA：自适应预算分配以实现参数有效的微调】[[paper](https://arxiv.org/pdf/2303.10512.pdf )]，[[code](https://github.com/QingruZhang/AdaLoRA )]

**【论文】**【微软 | 大型语言模型的语境忠实提示法】[[paper](https://arxiv.org/pdf/2303.11315.pdf )]

**【论文】**【KAUST | ChatGPT问，BLIP-2回答模型：面向丰富的视觉描述的自动提问】[[paper](https://arxiv.org/pdf/2303.06594.pdf )]，[[code](https://github.com/Vision-CAIR/ChatCaptioner)]

**【论文】**【ChatGPT真的可以取代知识图谱问答吗？ 】[[paper](https://arxiv.org/abs/2303.07992)]，[[paper翻译](https://mp.weixin.qq.com/s/cvBVgxCrreic6U6CU-YB-A )]

**【论文】**【Meta & 斯坦福大学推出FlexGen：用单个GPU进行大型语言模型的高吞吐量生成性推理】[[paper](https://arxiv.org/pdf/2303.06865.pdf )]，[[code](https://github.com/FMInference/FlexGen )]

**【论文】**【ChatGPT破圈的「秘密武器」：详解RLHF如何影响人类社会！ 】[[paper](https://arxiv.org/abs/2303.02891)]，[[blog](https://mp.weixin.qq.com/s/DCFhefWGQS5naYwT3o6neg )]

**【论文】**【探讨ChatGPT在对抗攻击和分布外泛化下的鲁棒性】[[paper](https://arxiv.org/pdf/2302.12095.pdf )]，[[code](https://github.com/microsoft/robustlearn)]

**【论文】**【复旦清华联合顶刊发文｜ChatGPT：潜力、前景和局限 】[[blog](https://mp.weixin.qq.com/s/1D62QuxXFDXWwwRXrB-Ivw )]，[[paper](https://link.springer.com/article/10.1631/FITEE.2300089 )]

**【论文】**【引导ChatGPT不要输出有害信息】[[paper](https://arxiv.org/pdf/2302.07459.pdf )]

**【论文】**【Junnan Li大佬发表最新多模态的杰作BLIP2】[[paper](https://arxiv.org/abs/2301.12597 )]，[[code](https://github.com/salesforce/LAVIS/tree/main/projects/blip2 )]，[[blog](https://mp.weixin.qq.com/s/xmSy4m7NheY8iComv7grxQ )]

**【论文】**【Instruction Tuning：无/少样本学习新范式 】[[paper](https://arxiv.org/abs/2109.01652)]，[[code](https://github.com/google-research/flan)]

**【论文】**【GPTScore：一种新的评估语言模型方法】[[paper](https://arxiv.org/abs/2302.04166 )]，[[code](https://github.com/jinlanfu/GPTScore )]

**【论文】**【ChatGPT内核：InstructGPT，基于反馈指令的PPO强化学习】[[blog](https://zhuanlan.zhihu.com/p/589747432)]，[[B站](https://www.bilibili.com/video/BV1hd4y187CR)]

**【论文】**【Fine-tune-CoT：小模型也能做推理，完美逆袭大模型 】[[paper](https://arxiv.org/pdf/2212.10071.pdf )]，[[code](https://github.com/itsnamgyu/reasoning-teacher)]

**【论文】**【ChatGPT的潜力解锁：自然语言处理中应用、优势、限制和未来方向的全面探索】[[paper](https://arxiv.org/pdf/2304.02017.pdf )]

**【论文】**【阿里巴巴&清华大学|大型语言模型在算术任务中的表现如何？】[[paper](https://arxiv.org/pdf/2304.02015.pdf )]，[[code](https://github.com/GanjinZero/math401-llm )]

**【代码】**【本科生60行代码教你手搓GPT大模型 】[[code](https://github.com/jaymody/picoGPT/tree/29e78cc52b58ed2c1c483ffea2eb46ff6bdec785)]


### GPT4

#### GPT4 官方文档
**【博客】**【GPT4_System_Card中文翻译】[[blog](https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Official/GPT-4_System_Card_zh.md)]

**【博客】**【GPT4_Technical_Report中文翻译】[[blog](https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Official/GPT4_Technical_Report_zh.md)]

#### GPT4 博客篇
**【纽约时报】**【GPT-4 令人印象深刻但仍在 10 个方面具有缺陷】[[blog](https://www.nytimes.com/2023/03/14/technology/openai-new-gpt4.html)]

**【Open AI】**【多模态大模型GPT-4的新突破】[[blog](https://hub.baai.ac.cn/view/24852)]

**【OpenAI】**【重磅发布GPT-4】[[blog](https://openai.com/research/gpt-4)]

**【OpenAI】**【GPT-4 创造者 Ilya Sutskever 谈 AI 幻觉和 AI 民主】[[blog](https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/?sh=7743f01e1218 )]

**【OpenAI】**【GPT-4创造者：第二次改变AI浪潮的方向】[[blog](https://mp.weixin.qq.com/s/rZBEDlxFVsVXoL5YUVU3XQ)]

**【OpenAI】**【当GPT-4进入北京市2022高考考场能有什么表现？】[[blog](https://mp.weixin.qq.com/s/N_j01KSuEKuVwCCD69G92g)]

**【博客】**[GPT4技术细节](https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Blog/GPT4_Technical_Detail.md)

**【博客】**[GPT4技术关键点总结](https://github.com/wshzd/ChatGPT-Summary/blob/main/GPT4/Blog/GPT4_Technical_Summary.md)

**【博客】**[GPT4和ChatGPT的效果对比](https://github.com/wshzd/ChatGPT-Summary/blob/main/ChatGPT_VS_GPT4/GPT4_VS_ChatGPT（from_nytimes）.md)

#### GPT4 论文篇
**【微软】**【用GPT-4进行指令调优】[[paper](https://arxiv.org/pdf/2304.03277.pdf )]，[[code](https://instruction-tuning-with-gpt-4.github.io/ )]

**【论文】**【点燃通用人工智能的火花：GPT-4的早期实验】[[原始paper](https://arxiv.org/pdf/2303.12712.pdf )]，[[中文版paper](https://event-cdn.baai.ac.cn/file/file-browser/waTXJn85fm3FPyDXpsZ4faGk47trjjYb.pdf  )]

**【论文】**【GPT4All：用GPT-3.5-Turbo的大规模数据提炼训练一个助理式聊天机器人】[[paper](https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf )]，[[code](https://github.com/nomic-ai/gpt4all )]

**【论文】**【美国东北大学：可以通过要求GPT4反思“你为什么错了？”来提高30%的性能】[[paper](https://arxiv.org/abs/2303.11366 )]，[[code](https://github.com/noahshinn024/reflexion )]

**【论文】**【对ChatGPT/GPT-4研究的总结以及对大型语言模型未来的展望】[[paper](https://arxiv.org/pdf/2304.01852.pdf )]

**【论文】**【评估日本医疗执照考试的GPT-4和ChatGPT】[[paper](https://arxiv.org/pdf/2303.18027.pdf )]

### Bard

【谷歌再次开放Bard访问权，向着ChatGPT发起再一次攻击】[[报名地址 ]([http://Bard.google.com](http://bard.google.com/) )]，[[blog](https://twitter.com/sundarpichai/status/1638180697352593408 )]，[[theverge](https://www.theverge.com/23649897/google-Bard-chatbot-search-engine)]

### Baize

【用ChatGPT训练羊驼：「Baize」开源，轻松构建专属模型】[[blog](https://mp.weixin.qq.com/s/zxElGfclNbBwTuDG4Qrxnw)]，[[paper](https://arxiv.org/abs/2304.01196  )]，[[code](https://github.com/project-baize/baize/blob/main/README.md )]，[[demo](https://huggingface.co/spaces/project-baize/baize-lora-7B )]

### GPT3.5

【GPT3.5试用地址 】[[试用地址](https://platform.openai.com/playground )]

### Claude 

【ChatGPT最强竞品Claude今日开放API】[[产品地址 ](https://www.anthropic.com/product)]，[[申请地址 ](https://www.anthropic.com/earlyaccess )]，[[API说明 ](https://console.anthropic.com/docs/api)]，[[blog](https://mp.weixin.qq.com/s/Wx5q-rEwG4sROvnewGxWrw)]

### ChatGLM-6B

【ChatGLM：千亿基座的对话模型开启内测 ⸺对应单卡版本开源】[[blog](https://chatglm.cn/blog )]，[[code](https://github.com/THUDM/ChatGLM-6B.git )]

### ChatYuan

【ChatYuan：基于PromptCLUE-large的中文对话开源大模型】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485655&idx=1&sn=ad80d8a17d4aaab90b17a79b638c712d&chksm=ced54b33f9a2c225ce292b4e3d5725a668d0bfc9fe0be610c847b31b61714ecf75c06dac1cb5&token=447941009&lang=zh_CN#rd)]

### Copilot X 

【GitHub Copilot X编辑器发布，大大提升编码速度 】[[blog](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/)]

### Dolly

【声称它 "**像ChatGPT一样神奇**"，但只需要**使用一台机器**在**不到三个小时的时间里**训练的数据少得多。】[[blog](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html )]，[[Databricks Inc地址](https://www.databricks.com )]

### JittorLLMs

【笔记本没有显卡也能跑大模型，具有高性能、配置要求低、中文支持好、可移植等特点 】[[code](https://github.com/Jittor/JittorLLMs)]

### OpenChatKit 

【ChatGPT开源平替OpenChatKit：参数量200亿，在4300万条指令上微调而成】[[blog](https://mp.weixin.qq.com/s/9Av3nhJLrcYAsBW9vVGjTw)]，[[code](https://github.com/togethercomputer/OpenChatKit)]，[[测试链接](https://huggingface.co/spaces/togethercomputer/OpenChatKit)]，[[模型权重](https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B)]，[[数据集](https://laion.ai/blog/oig-dataset/ )]

### LLaMA以及扩展

**【LLaMA】**【Meta开放小模型LLaMA，性能超过GPT-3】[[paper](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/ )]，[[code](https://github.com/facebookresearch/llama )]，[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485822&idx=1&sn=b365d93a0a08769aef77f34069da1422&chksm=ced54a9af9a2c38cd5779284b5e9ae573846153e7dc00961dc163664a657d6a3fa5c8c14c7d2&token=447941009&lang=zh_CN#rd)]

**【LLaMA评测】**[[blog](https://mp.weixin.qq.com/s/kImwfWWtXMmEDVOhJZ4dJg)]

**【Alpaca】**【斯坦福发布了一个由LLaMA 7B微调的模型Alpaca（羊驼），训练3小时，性能比肩GPT-3.5】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485890&idx=1&sn=2d1414fc3751353c31b946b3e954a465&chksm=ced54a26f9a2c330082e8c0014c96a6d9bef62e3581875031f203268a11fad09645a75b482b0&token=447941009&lang=zh_CN#rd)]，[[官网](https://crfm.stanford.edu/2023/03/13/alpaca.html )]，[[model](https://crfm.stanford.edu/alpaca)]，[[code](https://github.com/tatsu-lab/stanford_alpaca)]

**【Alpaca-CoT】**【Alpaca-CoT：多接口统一的轻量级LLM指令微调平台】[[code](https://github.com/PhoebusSi/Alpaca-CoT)]，[[官网](https://sota.jiqizhixin.com/project/alpaca-cot)]

**【ChatLLaMA】**【初创公司 Nebuly AI在LLaMA基础上加入RLHF 开源 ChatLLaMA 训练方法】[[code](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama )]

**【ColossalAI】**【完整复现ChatGPT全流程】[[code](https://github.com/hpcaitech/ColossalAI)]

**【ColossalChat】**【用于克隆 ChatGPT 和完整 RLHF 管道的开源解决方案】[[code](https://github.com/hpcaitech/ColossalAI)]，[[blog](https://syncedreview.com/2023/03/29/colossalchat-an-open-source-solution-for-cloning-chatgpt-with-a-complete-rlhf-pipeline/)]

**【FreedomGPT】**【FreedomGPT使用Electron 和 React构建，它是一个桌面应用程序，允许用户在他们的本地机器上运行LLaMA。 】[[官网地址](https://freedomgpt.com/)]

**【Koala 】**【加州大学BAIR团队提出Koala：学术研究的对话模型】[[blog_zh](https://hub.baai.ac.cn/view/25284)]，[[blog_en](https://bair.berkeley.edu/blog/2023/04/03/koala/)]

**【LLaMA-Adapter】**【**LLaMA-Adapter**，一种用于微调指令遵循[LLaMA](https://github.com/facebookresearch/llama)模型的轻量级自适应方法，使用[Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca)提供的 52K 数据。】[[paper](https://arxiv.org/pdf/2303.16199.pdf )]，[[code](https://github.com/ZrrSkywalker/LLaMA-Adapter )]

**【lit-llama】**【基于nanoGPT的LLaMA语言模型，支持量化、LoRA微调和预训练】[[code](https://github.com/Lightning-AI/lit-llama)]

**【llama.cpp】**【量化130亿参数LLaMA模型的llama.cpp，推理仅需4GB内存】[[blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485875&idx=1&sn=a4e09d31802c087f1f47bd292e380c19&chksm=ced54a57f9a2c341935b81aa27824dfa740beb7ce33289e0cb5190b5910040c0904371b7e8a0&token=447941009&lang=zh_CN#rd)]

**【llama.cpp优化版】**【Edge AI 变得更快|在 C/C++ 中移植 Facebook 的 LLaMA 模型】[[blog](https://hub.baai.ac.cn/view/25307)]

**【StackLLaMA】**【使用 RLHF 训练 LLaMA 的实践指南】[[blog_zh](https://hub.baai.ac.cn/view/25341)]，[[blog_en](https://huggingface.co/blog/stackllama)]

**【Vicuna】**【通过对从ShareGPT收集的用户共享对话进行微调的LLaMA训练，Vicuna-13B达到了OpenAI ChatGPT和Google Bard 90%*以上的质量 】[[Vicuna官网地址](https://vicuna.lmsys.org/)]，[[blog](https://hub.baai.ac.cn/view/25328)]

## 图像、视频生成

**【博客】**【Genmo Chat】【这是一款创造性的copilot，使用GPT-4和一大套生成人工智能工具创建并编辑您需要的任何视频或图像。 】[[blog](https://www.genmo.ai/)]

**【博客】**【BlenderGPT】【**一款基于GPT-4的扩展程序BlenderGPT开源，这是一个由GPT3/4驱动的全能AI编辑助手，为Blender提供支持** 】[[code](https://github.com/gd3kr/BlenderGPT)]

**【博客】**【Firefly】【Adobe制造了一个人工智能图像生成器--并表示它没有窃取艺术家的作品来做这件事 】[[blog](https://www.theverge.com/2023/3/21/23648315/adobe-firefly-ai-image-generator-announced)]

**【博客】**【Bing Image Creator】【微软推出Bing Image Creator，用户可根据文本提示创建图片】[[blog](https://techcrunch.com/2023/03/21/microsoft-brings-openais-dall-e-image-creator-to-the-new-bing/ )]

**【博客】**【Hugging Face 现已支持使用达摩院text-to-video模型从文本生成视频】[[模型地址 ](https://modelscope.cn/models/damo/text-to-video-synthesis/summary )]

**【论文】**【最新女娲大模型，中科院提出NUWA-XL：扩散模型中的扩散，生成超长视频】[[paper](https://arxiv.org/pdf/2303.12346.pdf )]，[[blog](https://msra-nuwa.azurewebsites.net/#/ )]

**【论文】**【艾伦AI研究院 & 华盛顿大学 | CHAMPAGNE：从大规模的网络视频中学习真实世界的对话】[[paper](https://arxiv.org/pdf/2303.09713.pdf )]，[[code](https://seungjuhan.me/champagne )]

**【论文】**【用AI直接复现你在想什么，Stable Diffusion逼真复现图像】[[paper](https://sites.google.com/view/stablediffusion-with-brain/ )]，[[blog](https://mp.weixin.qq.com/s/gIwj2eqNph8jHWOhYYEXIg)]

**【论文】**【Stable Diffusion公司新作Gen-1：基于扩散模型的视频合成新模型，加特效杠杠的！】[[paper](https://arxiv.org/pdf/2302.03011 )]，[[site](https://research.runwayml.com/gen1)]

**【论文】**【使用Diffusers 实现 ControlNet 高速推理】[[blog](https://mp.weixin.qq.com/s/k8rE9GrF97E-0TKJhih9kw)]

**【论文】**【文生图引入ControlNet，深度、边缘信息全能复用 】[[paper](https://arxiv.org/pdf/2302.05543.pdf)]，[[code](https://github.com/lllyasviel/ControlNet )]

**【论文】**【ChatGPT｜可用于AI绘画，效果飞升47% 】[[paper](https://arxiv.org/abs/2302.12192 )]

**【论文】**【智源研究院提出SegGPT： 一个用于分割上下文中所有事物的通用模型】[[paper](https://arxiv.org/pdf/2304.03284.pdf )]

## 代码生成

**【论文】**【北京大学：具有大语言模型的自我规划代码生成】[[paper](https://arxiv.org/pdf/2303.06689.pdf )]

**【论文】**【MIT最新研究：利用大预言模型生成Code】[[paper](https://arxiv.org/abs/2303.05510 )]，[[code](https://github.com/shunzh/Code-AI-Tree-Search )]，[[项目网址](https://codeaimcts.github.io/ )]

**【论文】**【Baldur: 基于大型语言模型的完全证明生成与修复】[[paper](https://arxiv.org/abs/2303.04910 )]

**【论文】**【MathPrompter: 基于大型语言模型的数学推理】[[paper](https://arxiv.org/abs/2303.05398 )]

**【论文】**【MIT最新研究：利用大语言模型生成Code】[[paper](https://arxiv.org/abs/2303.05510)]，[[code](https://github.com/shunzh/Code-AI-Tree-Search)]，[[官网地址](https://codeaimcts.github.io/)]

**【论文】**【CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X 】[[paper](https://arxiv.org/pdf/2303.17568.pdf )]，[[code](https://github.com/THUDM/CodeGeeX )]

**【论文】**【通过自我改进实现更好的代码语言模型，显著提高模型生成任务的性能】[[paper](https://arxiv.org/pdf/2304.01228.pdf )]

【工具】【Cursor：一个集成了 GPT-4 的国内直接可以访问的，优秀而强大的免费代码生成器，可以帮助你快速编写、编辑和讨论代码。 】[[官网地址](https://www.cursor.so/)]

## 语音生成

**【论文】**【文字、图片一键生成逼真音效，音频界AIGC来了 】[[paper](https://arxiv.org/abs/2301.12661)]，[[code](https://text-to-audio.github.io)]

## 多模态生成

**【论文】**【清华朱军团队开源UniDiffuser：首个基于Transformer的多模态扩散大模型！文图互生、改写全拿下！ 】[[paper](https://ml.cs.tsinghua.edu.cn/diffusion/unidiffuser.pdf)]，[[code](https://github.com/thu-ml/unidiffuser)]

## 欢迎共创

【👬🏻】欢迎Star ⭐️⭐️⭐️⭐️⭐️ && 提交 Pull requests 👏🏻👏🏻👏🏻

## 关于我

**个人主页**：wshzd.github.io

**微信公众号**：

![公众号二维码](images/ArronAI.jpg)

## 声明

以上部分资料来自网络整理，供大家学习参考，如有侵权，麻烦联系我删除！ 

WeChat：h18821656387
