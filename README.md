# Awesome-AGI

[![Anurag's GitHub stats](https://github-readme-stats.vercel.app/api?username=ArronAI007)](https://github.com/anuraghazra/github-readme-stats)

## æŠ€æœ¯äº¤æµ

æ¬¢è¿åŠ å…¥AIGCæŠ€æœ¯äº¤æµç¾¤ï¼Œä¸AIé¢†åŸŸä¸“å®¶å’Œå„è¡Œå„ä¸šçš„AIGCçˆ±å¥½è€…ä¸€èµ·äº¤æµæŠ€æœ¯ç†è®ºä¸è¡Œä¸šä¿¡æ¯ï¼ä¸ç®¡ä½ æ˜¯å­¦æœ¯ç•Œè¿˜æ˜¯å·¥ä¸šç•Œå®è·µè€…æˆ–çˆ±å¥½è€…ï¼Œéƒ½æ¬¢è¿åŠ å…¥ï¼

| äº¤æµç¾¤äºŒç»´ç                     | æ‹‰ä½ å…¥ç¾¤(å¤‡æ³¨AIGC-github) |
| ------------------------------- | :------------------------: |
| ![Arron](https://i.postimg.cc/FKrqKd6R/Wechat-IMG271.jpg) | ![Arron](https://i.postimg.cc/QMqj1DGc/Arron.jpg) |

## Table of Context
- [Model List](#Model-List)
- [LLM Pipeline](#LLM-Pipeline)
  - [LLM é¢„è®­ç»ƒ](#LLM-é¢„è®­ç»ƒ)
  - [LLM å¾®è°ƒ](#LLM-å¾®è°ƒ)
  - [LLM éƒ¨ç½²](#LLM-éƒ¨ç½²)
  - [LLM åˆ†å¸ƒå¼å¹¶è¡Œæ¡†æ¶](#LLM-åˆ†å¸ƒå¼å¹¶è¡Œæ¡†æ¶)
- [LLM åº”ç”¨](#LLM-åº”ç”¨)
  - [RAG](#RAG)
    - [RAGå®æˆ˜ä¸ç†è®º](#RAGå®æˆ˜ä¸ç†è®º)
    - [å‘é‡æ•°æ®åº“](#å‘é‡æ•°æ®åº“)
    - [RAGå¼€æºé¡¹ç›®](#RAGå¼€æºé¡¹ç›®)
  - [Agent](#Agent)
  - [LLM åº”ç”¨æ¡†æ¶](#LLM-åº”ç”¨æ¡†æ¶)
    - [LangChain](#LangChain)
    - [LlamaIndex](#LlamaIndex)
    - [TaskingAI](#TaskingAI)
- [LLM Concepts](#LLM-Concepts)
  - [Prompt Engineering](#Prompt-Engineering)
  - [RLHF](#RLHF)
  - [LLM æ‰©è¯è¡¨](#LLM-æ‰©è¯è¡¨)
  - [LLM é•¿æ–‡æœ¬](#LLM-é•¿æ–‡æœ¬)
  - [LLM å¹»è§‰](#LLM-å¹»è§‰)
  - [LLM å¯æ§æ€§ä¸å®‰å…¨](#LLM-å¯æ§æ€§ä¸å®‰å…¨)
  - [LLM æ–‡æœ¬æ£€æµ‹](#LLM-æ–‡æœ¬æ£€æµ‹)

## Model List

å¤§æ¨¡å‹å±‚å‡ºä¸ç©·ï¼Œæˆ‘å¯¹ä¸»æµå¤§æ¨¡å‹æŒ‰ç…§å¦‚ä¸‹åˆ†ç±»ä½“ç³»è¿›è¡Œåˆ†ç±»ï¼š

1ï¼‰baichuanã€ChatGLMå’ŒLLaMAåŠå…¶æ‰©å±•æ¨¡å‹ï¼›

2ï¼‰æŒ‰ç…§é€šç”¨é¢†åŸŸï¼ˆåŒ…æ‹¬æ–‡æœ¬ã€ä»£ç ã€å›¾åƒ/è§†é¢‘ã€éŸ³é¢‘ã€å¤šæ¨¡æ€ï¼‰å’Œå‚ç›´é¢†åŸŸï¼ˆæ³•å¾‹ã€åŒ»ç–—ã€é‡‘èã€ç¯å¢ƒã€ç½‘ç»œå®‰å…¨ã€æ•™è‚²ã€äº¤é€šä»¥åŠå…¶ä»–ï¼‰

æ›´å¤šè¯·å‚è€ƒã€[Model List](https://github.com/ArronAI007/Awesome-AGI/blob/main/Model%20List/README.md)ã€‘ã€‚

dair-aiåŒæ ·ä¹Ÿæ•´ç†äº†å¾ˆå¤šå…³äºLLMå’Œç»å…¸è®ºæ–‡ï¼Œæ„Ÿå…´è¶£çš„è¯»è€…å¯ä»¥å‚è€ƒï¼šã€[ML Papers Explained](https://github.com/dair-ai/ML-Papers-Explained)ã€‘

3) å›½å†…å¤–å¤§æ¨¡å‹APIçš„è°ƒç”¨æ¡ˆä¾‹ï¼Œè¯·å‚è€ƒã€[è¯­è¨€å¤§æ¨¡å‹](https://github.com/ArronAI007/Awesome-AGI/tree/main/Model%20List/LLM)ã€‘ï¼Œã€[è¯­è¨€å¤§æ¨¡å‹](https://github.com/ArronAI007/Awesome-AGI/tree/main/Model%20List/MLLM)ã€‘å’Œã€[OpenAI](https://github.com/ArronAI007/Awesome-AGI/tree/main/Model%20List/OpenAI)ã€‘

---

## LLM Pipeline

### LLM é¢„è®­ç»ƒ

LLMé¢„è®­ç»ƒã€å¾®è°ƒä½¿ç”¨çš„éƒ¨åˆ†æ•°æ®é›†ï¼Œæ›´å¤šè¯·å‚è€ƒã€[DataSet](https://github.com/ArronAI007/Awesome-AGI/blob/main/DataSet/README.md)ã€‘

---

### LLM å¾®è°ƒ

éšç€ChatGPTçš„å‘å¸ƒï¼Œæ ‡å¿—ç€å¤§æ¨¡å‹æ—¶ä»£å·²æ¥ä¸´ï¼Œç„¶è€Œé€šç”¨é¢†åŸŸçš„å¤§æ¨¡å‹åœ¨ä¼ä¸šå‚ç›´é¢†åŸŸä¸­æœªå¿…ä¼šè¡¨ç°çš„å¥½ï¼Œå› æ­¤ä¼šå¯¹é€šç”¨é¢†åŸŸå¤§æ¨¡å‹è¿›è¡Œå¾®è°ƒæ¥é€‚é…å‚ç›´é¢†åŸŸçŸ¥è¯†ã€‚

**å¤§æ¨¡å‹çš„å¾®è°ƒæŠ€æœ¯ï¼Œä»ä¸åŒçš„æ–¹é¢ï¼Œæœ‰ä¸åŒçš„åˆ†ç±»ï¼š**

ä»å‚æ•°è§„æ¨¡æ¥è¯´ï¼Œå¯ä»¥ç®€å•åˆ†ä¸º**å…¨å‚æ•°å¾®è°ƒ**å’Œ**é«˜æ•ˆå‚æ•°å¾®è°ƒ**ã€‚å‰è€…ä¸€èˆ¬æ˜¯ç”¨é¢„è®­ç»ƒæ¨¡å‹ä½œä¸ºåˆå§‹åŒ–æƒé‡ï¼Œåœ¨ç‰¹å®šæ•°æ®é›†ä¸Šç»§ç»­è®­ç»ƒï¼Œå…¨éƒ¨å‚æ•°éƒ½æ›´æ–°çš„æ–¹æ³•ã€‚è€Œåè€…åˆ™æ˜¯æœŸæœ›ç”¨æ›´å°‘çš„èµ„æºå®Œæˆæ¨¡å‹å‚æ•°çš„æ›´æ–°ï¼ŒåŒ…æ‹¬åªæ›´æ–°ä¸€éƒ¨åˆ†å‚æ•°æˆ–è€…è¯´é€šè¿‡å¯¹å‚æ•°è¿›è¡ŒæŸç§ç»“æ„åŒ–çº¦æŸï¼Œä¾‹å¦‚ç¨€ç–åŒ–æˆ–ä½ç§©è¿‘ä¼¼æ¥é™ä½å¾®è°ƒçš„å‚æ•°æ•°é‡ã€‚

å¦‚æœæŒ‰ç…§åœ¨æ¨¡å‹å“ªä¸ªé˜¶æ®µä½¿ç”¨å¾®è°ƒï¼Œæˆ–è€…æ ¹æ®æ¨¡å‹å¾®è°ƒçš„ç›®æ ‡æ¥åŒºåˆ†ï¼Œä¹Ÿå¯ä»¥ä»æç¤ºå¾®è°ƒã€æŒ‡ä»¤å¾®è°ƒã€æœ‰ç›‘ç£å¾®è°ƒçš„æ–¹å¼æ¥ã€‚
é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å¯ä»¥ç²—ç•¥åˆ†ä¸ºä»¥ä¸‹ä¸‰å¤§ç±»ï¼š

- å¢åŠ é¢å¤–å‚æ•°ï¼ˆAddition-Basedï¼‰
- é€‰å–ä¸€éƒ¨åˆ†å‚æ•°æ›´æ–°ï¼ˆSelection-Basedï¼‰
- å¼•å…¥é‡å‚æ•°åŒ–ï¼ˆReparametrization-Basedï¼‰

è€Œåœ¨å¢åŠ é¢å¤–å‚æ•°è¿™ç±»æ–¹æ³•ä¸­ï¼Œåˆä¸»è¦åˆ†ä¸ºç±»é€‚é…å™¨ï¼ˆAdapter-likeï¼‰æ–¹æ³•å’Œè½¯æç¤ºï¼ˆSoft promptsï¼‰ä¸¤ä¸ªå°ç±»ã€‚
å¢åŠ é¢å¤–å‚æ•° Addition-Basedï¼Œå¦‚ï¼šPrefix Tuningã€Prompt Tuningã€Adapter TuningåŠå…¶å˜ä½“
é€‰å–ä¸€éƒ¨åˆ†å‚æ•°æ›´æ–° Selection-Basedï¼Œå¦‚ï¼šBitFit
å¼•å…¥é‡å‚æ•°åŒ– Reparametrization-Basedï¼Œå¦‚ï¼šLoRAã€AdaLoRAã€QLoRA
æ··åˆé«˜æ•ˆå¾®è°ƒï¼Œå¦‚ï¼šMAM Adapterã€UniPELT


ä¸‹å›¾æ˜¯ç›®å‰ä¸»æµPEFTæŠ€æœ¯çš„æ€»ç»“ï¼š

![Peft](https://i.postimg.cc/fT3VcWML/peft.png)

[PEFT](https://github.com/huggingface/peft)ä»“åº“æ˜¯ä¸€ä¸ªç”¨äºå¾®è°ƒå¤§æ¨¡å‹çš„å·¥å…·åº“ï¼Œæä¾›äº†å¤šç§é«˜æ•ˆå¾®è°ƒæŠ€æœ¯çš„å®ç°ã€‚

ä¸‹é¢æŒ‰ç…§LoRAåŠå…¶æ‰©å±•æ¨¡å‹å’Œå…¶ä»–å¾®è°ƒæ–¹æ³•åˆ†åˆ«è¿›è¡Œæ€»ç»“ï¼š

#### LoRAåŠå…¶æ‰©å±•æŠ€æœ¯

| Peft | Description| Paper | Code | Blog |
| --- | --- | --- | --- | --- | 
| LoRA | 1)Transformerçš„æƒé‡çŸ©é˜µåŒ…æ‹¬Attentionæ¨¡å—é‡Œç”¨äºè®¡ç®—query, key, valueçš„Wqï¼ŒWkï¼ŒWvä»¥åŠå¤šå¤´attentionçš„Woï¼Œä»¥åŠMLPå±‚çš„æƒé‡çŸ©é˜µï¼ŒLoRAåªåº”ç”¨äºAttentionæ¨¡å—ä¸­çš„4ç§æƒé‡çŸ©é˜µï¼Œè€Œä¸”é€šè¿‡æ¶ˆèå®éªŒå‘ç°åŒæ—¶è°ƒæ•´ Wq å’Œ Wv ä¼šäº§ç”Ÿæœ€ä½³ç»“æœã€‚2)å®éªŒè¿˜å‘ç°ï¼Œä¿è¯æƒé‡çŸ©é˜µçš„ç§ç±»çš„æ•°é‡æ¯”èµ·å¢åŠ éšè—å±‚ç»´åº¦ræ›´ä¸ºé‡è¦ï¼Œå¢åŠ rå¹¶ä¸ä¸€å®šèƒ½è¦†ç›–æ›´åŠ æœ‰æ„ä¹‰çš„å­ç©ºé—´ã€‚3)å…³äºç§©çš„é€‰æ‹©ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼Œrankä¸º4ï¼Œ8ï¼Œ16å³å¯ã€‚4)å®éªŒä¹Ÿå‘ç°ï¼Œåœ¨ä¼—å¤šæ•°æ®é›†ä¸ŠLoRAåœ¨åªè®­ç»ƒæå°‘é‡å‚æ•°çš„å‰æä¸‹ï¼Œæœ€ç»ˆåœ¨æ€§èƒ½ä¸Šèƒ½å’Œå…¨é‡å¾®è°ƒåŒ¹é…ï¼Œç”šè‡³åœ¨æŸäº›ä»»åŠ¡ä¸Šä¼˜äºå…¨é‡å¾®è°ƒã€‚| [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf) | [LoRA Code](https://github.com/microsoft/LoRA) |  | 
| LoRA+ | LoRA+é€šè¿‡ä¸ºçŸ©é˜µaå’Œbå¼•å…¥ä¸åŒçš„å­¦ä¹ ç‡ï¼ŒçŸ©é˜µBçš„åˆå§‹åŒ–ä¸º0ï¼Œæ‰€ä»¥éœ€è¦æ¯”éšæœºåˆå§‹åŒ–çš„çŸ©é˜µaéœ€è¦æ›´å¤§çš„æ›´æ–°æ­¥éª¤ã€‚é€šè¿‡å°†çŸ©é˜µBçš„å­¦ä¹ ç‡è®¾ç½®ä¸ºçŸ©é˜µAçš„16å€ï¼Œä½œè€…å·²ç»èƒ½å¤Ÿåœ¨æ¨¡å‹ç²¾åº¦ä¸Šè·å¾—å°å¹…æé«˜(çº¦2%)ï¼ŒåŒæ—¶å°†RoBERTaæˆ–lama-7bç­‰æ¨¡å‹çš„è®­ç»ƒæ—¶é—´åŠ å¿«2å€ã€‚ | [LoRA+: Efficient Low Rank Adaptation of Large Models](https://arxiv.org/abs/2402.12354) |  |  | 
| AdaLoRA | AdaLoRAæ˜¯å¯¹LoRAçš„ä¸€ç§æ”¹è¿›ï¼Œå®ƒæ ¹æ®é‡è¦æ€§è¯„åˆ†åŠ¨æ€åˆ†é…å‚æ•°é¢„ç®—ç»™æƒé‡çŸ©é˜µã€‚å…·ä½“åšæ³•å¦‚ä¸‹ï¼š1)è°ƒæ•´å¢é‡çŸ©åˆ†é…ã€‚AdaLoRAå°†å…³é”®çš„å¢é‡çŸ©é˜µåˆ†é…é«˜ç§©ä»¥æ•æ‰æ›´ç²¾ç»†å’Œä»»åŠ¡ç‰¹å®šçš„ä¿¡æ¯ï¼Œè€Œå°†è¾ƒä¸é‡è¦çš„çŸ©é˜µçš„ç§©é™ä½ï¼Œä»¥é˜²æ­¢è¿‡æ‹Ÿåˆå¹¶èŠ‚çœè®¡ç®—é¢„ç®—ã€‚2)ä»¥å¥‡å¼‚å€¼åˆ†è§£çš„å½¢å¼å¯¹å¢é‡æ›´æ–°è¿›è¡Œå‚æ•°åŒ–ï¼Œå¹¶æ ¹æ®é‡è¦æ€§æŒ‡æ ‡è£å‰ªæ‰ä¸é‡è¦çš„å¥‡å¼‚å€¼ï¼ŒåŒæ—¶ä¿ç•™å¥‡å¼‚å‘é‡ã€‚ç”±äºå¯¹ä¸€ä¸ªå¤§çŸ©é˜µè¿›è¡Œç²¾ç¡®SVDåˆ†è§£çš„è®¡ç®—æ¶ˆè€—éå¸¸å¤§ï¼Œè¿™ç§æ–¹æ³•é€šè¿‡å‡å°‘å®ƒä»¬çš„å‚æ•°é¢„ç®—æ¥åŠ é€Ÿè®¡ç®—ï¼ŒåŒæ—¶ï¼Œä¿ç•™æœªæ¥æ¢å¤çš„å¯èƒ½æ€§å¹¶ç¨³å®šè®­ç»ƒã€‚3)åœ¨è®­ç»ƒæŸå¤±ä¸­æ·»åŠ äº†é¢å¤–çš„æƒ©ç½šé¡¹ï¼Œä»¥è§„èŒƒå¥‡å¼‚çŸ©é˜µPå’ŒQçš„æ­£äº¤æ€§ï¼Œä»è€Œé¿å…SVDçš„å¤§é‡è®¡ç®—å¹¶ç¨³å®šè®­ç»ƒã€‚ | [AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2303.10512) | [AdaLoRA Code](https://github.com/QingruZhang/AdaLoRA) |  | 
| QLoRA | QLoRAä½¿ç”¨ä¸€ç§æ–°é¢–çš„é«˜ç²¾åº¦æŠ€æœ¯å°†é¢„è®­ç»ƒæ¨¡å‹é‡åŒ–ä¸º 4 bitï¼Œç„¶åæ·»åŠ ä¸€å°ç»„å¯å­¦ä¹ çš„ä½ç§©é€‚é…å™¨æƒé‡ï¼Œè¿™äº›æƒé‡é€šè¿‡é‡åŒ–æƒé‡çš„åå‘ä¼ æ’­æ¢¯åº¦è¿›è¡Œå¾®è°ƒã€‚QLORA æœ‰ä¸€ç§ä½ç²¾åº¦å­˜å‚¨æ•°æ®ç±»å‹ï¼ˆ4 bitï¼‰ï¼Œè¿˜æœ‰ä¸€ç§è®¡ç®—æ•°æ®ç±»å‹ï¼ˆBFloat16ï¼‰ã€‚å®é™…ä¸Šï¼Œè¿™æ„å‘³ç€æ— è®ºä½•æ—¶ä½¿ç”¨ QLoRA æƒé‡å¼ é‡ï¼Œæˆ‘ä»¬éƒ½ä¼šå°†å¼ é‡åé‡åŒ–ä¸º BFloat16ï¼Œç„¶åæ‰§è¡Œ 16 ä½çŸ©é˜µä¹˜æ³•ã€‚QLoRAæå‡ºäº†ä¸¤ç§æŠ€æœ¯å®ç°é«˜ä¿çœŸ 4 bitå¾®è°ƒâ€”â€”4 bit NormalFloat(NF4) é‡åŒ–å’ŒåŒé‡åŒ–ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†åˆ†é¡µä¼˜åŒ–å™¨ï¼Œä»¥é˜²æ­¢æ¢¯åº¦æ£€æŸ¥ç‚¹æœŸé—´çš„å†…å­˜å³°å€¼ï¼Œä»è€Œå¯¼è‡´å†…å­˜ä¸è¶³çš„é”™è¯¯ï¼Œè¿™äº›é”™è¯¯åœ¨è¿‡å»ä½¿å¾—å¤§å‹æ¨¡å‹éš¾ä»¥åœ¨å•å°æœºå™¨ä¸Šè¿›è¡Œå¾®è°ƒã€‚ | [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314) | [QLoRA Code](https://github.com/artidoro/qlora) |  | 
| DoRA | DoRAï¼ˆWeight-Decomposed Low-Rank Adaptationï¼šæƒé‡åˆ†è§£ä½é˜¶é€‚åº”ï¼‰æ˜¯ç”±NVIDIAæœ€æ–°æå‡ºçš„ä¸€ç§æ–°çš„å‚æ•°é«˜æ•ˆçš„å¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ã€‚DoRAæ—¨åœ¨é€šè¿‡åˆ†è§£é¢„è®­ç»ƒæƒé‡ä¸ºå¹…åº¦ï¼ˆmagnitudeï¼‰å’Œæ–¹å‘ï¼ˆdirectionï¼‰ä¸¤ä¸ªç»„æˆéƒ¨åˆ†ç„¶ååˆ†åˆ«å¾®è°ƒï¼Œæ¥æé«˜å¾®è°ƒçš„å­¦ä¹ èƒ½åŠ›å’Œè®­ç»ƒç¨³å®šæ€§ï¼ŒåŒæ—¶é¿å…é¢å¤–çš„æ¨ç†å¼€é”€ï¼Œå®ƒç‰¹åˆ«é€‚ç”¨äºä¸LoRAï¼ˆLow-Rank Adaptationï¼‰ç»“åˆä½¿ç”¨ã€‚ | [DoRA: Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/pdf/2402.09353.pdf) | [DoRA Code](https://github.com/catid/dora) |  | 
| PiSSAæ–¹æ³• | ä»…ä¿®æ”¹Loraåˆå§‹åŒ–æ–¹å¼æ˜¾è‘—æé«˜æ¨¡å‹å¾®è°ƒæ•ˆæœ | [PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models](https://arxiv.org/abs/2404.02948) | [PiSSA Code](https://github.com/GraphPKU/PiSSA) | [PiSSA Blog](https://zhuanlan.zhihu.com/p/687583780) | 
| MOELora | MOELoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°† MOE å’Œ LoRA ç»“åˆèµ·æ¥ï¼Œä»¥å®ç°å¤šä»»åŠ¡å­¦ä¹ å’Œå‚æ•°é«˜æ•ˆå¾®è°ƒã€‚MOELoRA ç”±ä¸¤ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼šMOE å’Œ LoRAã€‚MOE ç”¨äºå¤šä»»åŠ¡å­¦ä¹ ï¼ŒLoRA ç”¨äºå‚æ•°é«˜æ•ˆå¾®è°ƒã€‚MOELoRA é€šè¿‡ MOE çš„å¤šä»»åŠ¡å­¦ä¹ èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨äº†æœ‰é™çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼ŒåŒæ—¶é€šè¿‡ LoRA çš„å‚æ•°é«˜æ•ˆå¾®è°ƒèƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°æé«˜äº†å¤šä»»åŠ¡åŒ»å­¦åº”ç”¨çš„æ€§èƒ½ã€‚ | [MOELoRA: An MOE-based Parameter Efficient Fine-Tuning Method for Multi-task Medical Applications](https://arxiv.org/abs/2310.18339) | [MOELora Code](https://github.com/liuqidong07/MOELoRA-peft) |  | 
| LoRA-FA | LoRA-faï¼Œæ˜¯LoRAä¸Frozen-Açš„ç¼©å†™ï¼Œåœ¨LoRA-FAä¸­ï¼ŒçŸ©é˜µAåœ¨åˆå§‹åŒ–åè¢«å†»ç»“ï¼Œå› æ­¤ä½œä¸ºéšæœºæŠ•å½±ã€‚çŸ©é˜µBä¸æ˜¯æ·»åŠ æ–°çš„å‘é‡ï¼Œè€Œæ˜¯åœ¨ç”¨é›¶åˆå§‹åŒ–ä¹‹åè¿›è¡Œè®­ç»ƒ(å°±åƒåœ¨åŸå§‹LoRAä¸­ä¸€æ ·)ã€‚è¿™å°†å‚æ•°æ•°é‡å‡åŠï¼ŒåŒæ—¶å…·æœ‰ä¸æ™®é€šLoRAç›¸å½“çš„æ€§èƒ½ã€‚ | [LoRA-FA: Memory-efficient Low-rank Adaptation for Large Language Models Fine-tuning
](https://arxiv.org/abs/2308.03303) |  |  | 
| LoRa-drop | LoraçŸ©é˜µå¯ä»¥æ·»åŠ åˆ°ç¥ç»ç½‘ç»œçš„ä»»ä½•ä¸€å±‚ã€‚LoRA-dropåˆ™å¼•å…¥äº†ä¸€ç§ç®—æ³•æ¥å†³å®šå“ªäº›å±‚ç”±LoRAå¾®è°ƒï¼Œå“ªäº›å±‚ä¸éœ€è¦ã€‚ | [LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation](https://arxiv.org/abs/2402.07721) |  |  | 
| Delta-LoRA | Delta-LoRAçš„ä½œè€…æå‡ºç”¨ABçš„æ¢¯åº¦æ¥æ›´æ–°çŸ©é˜µW, ABçš„æ¢¯åº¦æ˜¯A*Båœ¨è¿ç»­ä¸¤ä¸ªæ—¶é—´æ­¥é•¿çš„å·®ã€‚è¿™ä¸ªæ¢¯åº¦ç”¨è¶…å‚æ•°Î»è¿›è¡Œç¼©æ”¾ï¼ŒÎ»æ§åˆ¶æ–°è®­ç»ƒå¯¹é¢„è®­ç»ƒæƒé‡çš„å½±å“åº”è¯¥æœ‰å¤šå¤§ã€‚ | [Delta-LoRA: Fine-Tuning High-Rank Parameters with the Delta of Low-Rank Matrices](https://arxiv.org/abs/2309.02411) |  |  | 

#### å…¶ä»–å¾®è°ƒæŠ€æœ¯

| Peft | Description| Paper | Code | Blog |
| --- | --- | --- | --- | --- | 
| Instruction Tuning | æŒ‡ä»¤å¾®è°ƒå¯ä»¥è¢«è§†ä¸ºæœ‰ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼ŒSFTï¼‰çš„ä¸€ç§ç‰¹æ®Šå½¢å¼ã€‚ä½†æ˜¯ï¼Œå®ƒä»¬çš„ç›®æ ‡ä¾ç„¶æœ‰å·®åˆ«ã€‚SFTæ˜¯ä¸€ç§ä½¿ç”¨æ ‡è®°æ•°æ®å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒçš„è¿‡ç¨‹ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚è€ŒæŒ‡ä»¤å¾®è°ƒæ˜¯ä¸€ç§é€šè¿‡åœ¨åŒ…æ‹¬ï¼ˆæŒ‡ä»¤ï¼Œè¾“å‡ºï¼‰å¯¹çš„æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿‡ç¨‹ï¼Œä»¥å¢å¼ºLLMsçš„èƒ½åŠ›å’Œå¯æ§æ€§ã€‚| [nstruction Tuning for Large Language Models: A Survey](https://arxiv.org/abs/2308.10792) | [Instruction Tuning Code](https://github.com/xiaoya-li/Instruction-Tuning-Survey) |  | 
| BitFit | BitFitæ˜¯ä¸€ç§ç¨€ç–çš„å¾®è°ƒæ–¹æ³•ï¼Œå®ƒè®­ç»ƒæ—¶åªæ›´æ–°biasçš„å‚æ•°æˆ–è€…éƒ¨åˆ†biaså‚æ•° | [BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models](https://arxiv.org/abs/2106.10199) | [BitFit Code](https://github.com/benzakenelad/BitFit) |  | 
| Prefix Tuning | Prefix Tuningæå‡ºå›ºå®šé¢„è®­ç»ƒLMï¼Œä¸ºLMæ·»åŠ å¯è®­ç»ƒï¼Œä»»åŠ¡ç‰¹å®šçš„å‰ç¼€ï¼Œè¿™æ ·å°±å¯ä»¥ä¸ºä¸åŒä»»åŠ¡ä¿å­˜ä¸åŒçš„å‰ç¼€ï¼Œå¾®è°ƒæˆæœ¬ä¹Ÿå°ï¼›åŒæ—¶ï¼Œè¿™ç§Prefixå®é™…å°±æ˜¯è¿ç»­å¯å¾®çš„Virtual Tokenï¼ˆSoft Prompt/Continuous Promptï¼‰ï¼Œç›¸æ¯”ç¦»æ•£çš„Tokenï¼Œæ›´å¥½ä¼˜åŒ–ï¼Œæ•ˆæœæ›´å¥½ã€‚ | [Prefix-Tuning: Optimizing Continuous Prompts for Generation](https://arxiv.org/abs/2101.00190) | [Prefix Tuning Code](https://github.com/huggingface/peft/blob/main/src/peft/tuners/prefix_tuning/model.py) |  | 
| Prompt Tuning | Prompt Tuningï¼Œè¯¥æ–¹æ³•å¯ä»¥çœ‹ä½œæ˜¯Prefix Tuningçš„ç®€åŒ–ç‰ˆæœ¬ï¼Œå®ƒç»™æ¯ä¸ªä»»åŠ¡å®šä¹‰äº†è‡ªå·±çš„Promptï¼Œç„¶åæ‹¼æ¥åˆ°æ•°æ®ä¸Šä½œä¸ºè¾“å…¥ï¼Œä½†åªåœ¨è¾“å…¥å±‚åŠ å…¥prompt tokensï¼Œå¹¶ä¸”ä¸éœ€è¦åŠ å…¥ MLP è¿›è¡Œè°ƒæ•´æ¥è§£å†³éš¾è®­ç»ƒçš„é—®é¢˜ã€‚ | [The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/abs/2104.08691) | [Prompt Tuning Code](https://github.com/huggingface/peft/blob/main/src/peft/tuners/prompt_tuning/model.py) |  | 
| P-Tuning | P-Tuningï¼Œè®¾è®¡äº†ä¸€ç§è¿ç»­å¯å¾®çš„virtual tokenï¼ˆåŒPrefix-Tuningç±»ä¼¼ï¼‰ã€‚å°†Promptè½¬æ¢ä¸ºå¯ä»¥å­¦ä¹ çš„Embeddingå±‚ï¼Œå¹¶ç”¨MLP+LSTMçš„æ–¹å¼æ¥å¯¹Prompt Embeddingè¿›è¡Œä¸€å±‚å¤„ç†ã€‚å€ŸåŠ©P-tuningï¼ŒGPTåœ¨SuperGLUEä¸Šçš„æˆç»©é¦–æ¬¡è¶…è¿‡äº†åŒç­‰çº§åˆ«çš„BERTæ¨¡å‹ï¼Œè¿™é¢ è¦†äº†ä¸€ç›´ä»¥æ¥â€œGPTä¸æ“…é•¿NLUâ€çš„ç»“è®ºï¼Œä¹Ÿæ˜¯è¯¥è®ºæ–‡å‘½åçš„ç¼˜ç”±ã€‚ | [GPT Understands, Too](https://arxiv.org/abs/2103.10385) | [P-Tuning Code](https://github.com/huggingface/peft/blob/main/src/peft/tuners/p_tuning/model.py) |  | 
| P-Tuning V2 | P-Tuning çš„é—®é¢˜æ˜¯åœ¨å°å‚æ•°é‡æ¨¡å‹ä¸Šè¡¨ç°å·®ã€‚ ç›¸æ¯” Prompt Tuning å’Œ P-tuning çš„æ–¹æ³•ï¼Œ P-tuning v2 æ–¹æ³•åœ¨æ¯ä¸€å±‚åŠ å…¥äº† Prompts tokens ä½œä¸ºè¾“å…¥ã€‚ä¸P-Tuningç›¸æ¯”ï¼Œåšäº†å¦‚ä¸‹æ”¹å˜ï¼š1ï¼‰ç§»é™¤é‡å‚æ•°åŒ–çš„ç¼–ç å™¨ï¼›2)é’ˆå¯¹ä¸åŒä»»åŠ¡é‡‡ç”¨ä¸åŒçš„æç¤ºé•¿åº¦;3)å¼•å…¥å¤šä»»åŠ¡å­¦ä¹ ;4)å›å½’ä¼ ç»Ÿçš„åˆ†ç±»æ ‡ç­¾èŒƒå¼ï¼Œè€Œä¸æ˜¯æ˜ å°„å™¨ | [P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](https://arxiv.org/abs/2110.07602) | [P-Tuning-V2 Code](https://github.com/THUDM/P-tuning-v2) |  | 
| Adapter Tuning | Adapter åœ¨é¢„è®­ç»ƒæ¨¡å‹æ¯å±‚ä¸­æ’å…¥ç”¨äºä¸‹æ¸¸ä»»åŠ¡çš„å‚æ•°ï¼ˆé’ˆå¯¹æ¯ä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼Œä»…å¢åŠ 3.6%çš„å‚æ•°ï¼‰ï¼Œåœ¨å¾®è°ƒæ—¶å°†æ¨¡å‹ä¸»ä½“å†»ç»“ï¼Œä»…è®­ç»ƒç‰¹å®šäºä»»åŠ¡çš„å‚æ•°ï¼Œä»è€Œå‡å°‘äº†è®­ç»ƒæ—¶çš„ç®—åŠ›å¼€é”€ã€‚Adapter Tuning è®¾è®¡äº†Adapterç»“æ„ï¼Œå¹¶å°†å…¶åµŒå…¥Transformerçš„ç»“æ„é‡Œé¢ï¼Œé’ˆå¯¹æ¯ä¸€ä¸ªTransformerå±‚ï¼Œå¢åŠ äº†ä¸¤ä¸ªAdapterç»“æ„ï¼Œåˆ†åˆ«æ˜¯å¤šå¤´æ³¨æ„åŠ›çš„æŠ•å½±ä¹‹åå’Œç¬¬äºŒä¸ªfeed-forwardå±‚ä¹‹åã€‚åœ¨è®­ç»ƒæ—¶ï¼Œå›ºå®šä½åŸæ¥é¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°ä¸å˜ï¼Œåªå¯¹æ–°å¢çš„ Adapter ç»“æ„å’Œ Layer Norm å±‚è¿›è¡Œå¾®è°ƒï¼Œä»è€Œä¿è¯äº†è®­ç»ƒçš„é«˜æ•ˆæ€§ã€‚ | [Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/abs/1902.00751) | [Adapter Tuning Code](https://github.com/google-research/adapter-bert) |  | 
| AdapterFusion | Adapter Fusionï¼Œä¸€ç§èåˆå¤šä»»åŠ¡ä¿¡æ¯çš„Adapterçš„å˜ä½“ï¼Œåœ¨ Adapter çš„åŸºç¡€ä¸Šè¿›è¡Œä¼˜åŒ–ï¼Œé€šè¿‡å°†å­¦ä¹ è¿‡ç¨‹åˆ†ä¸ºä¸¤é˜¶æ®µæ¥æå‡ä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ã€‚1ï¼‰çŸ¥è¯†æå–é˜¶æ®µï¼šåœ¨ä¸åŒä»»åŠ¡ä¸‹å¼•å…¥å„è‡ªçš„Adapteræ¨¡å—ï¼Œç”¨äºå­¦ä¹ ç‰¹å®šä»»åŠ¡çš„ä¿¡æ¯ã€‚2ï¼‰çŸ¥è¯†ç»„åˆé˜¶æ®µï¼šå°†é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ä¸ç‰¹å®šä»»åŠ¡çš„Adapterå‚æ•°å›ºå®šï¼Œå¼•å…¥æ–°å‚æ•°ï¼ˆAdapterFusionï¼‰æ¥å­¦ä¹ ç»„åˆå¤šä¸ªAdapterä¸­çš„çŸ¥è¯†ï¼Œä»¥æé«˜æ¨¡å‹åœ¨ç›®æ ‡ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ | [AdapterFusion: Non-Destructive Task Composition for Transfer Learning](https://arxiv.org/abs/2005.00247) |  |  | 
| AdapterDrop | ä½œè€…é€šè¿‡å¯¹Adapterçš„è®¡ç®—æ•ˆç‡è¿›è¡Œåˆ†æï¼Œå‘ç°ä¸å…¨é‡å¾®è°ƒç›¸æ¯”ï¼ŒAdapteråœ¨è®­ç»ƒæ—¶å¿«60%ï¼Œä½†æ˜¯åœ¨æ¨ç†æ—¶æ…¢4%-6%ã€‚åŸºäºæ­¤ï¼Œä½œè€…æå‡ºäº†AdapterDropæ–¹æ³•ç¼“è§£è¯¥é—®é¢˜ã€‚AdapterDrop åœ¨ä¸å½±å“ä»»åŠ¡æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œå¯¹AdapteråŠ¨æ€é«˜æ•ˆçš„ç§»é™¤ï¼Œå°½å¯èƒ½çš„å‡å°‘æ¨¡å‹çš„å‚æ•°é‡ï¼Œæé«˜æ¨¡å‹åœ¨åå‘ä¼ æ’­ï¼ˆè®­ç»ƒï¼‰å’Œæ­£å‘ä¼ æ’­ï¼ˆæ¨ç†ï¼‰æ—¶çš„æ•ˆç‡ã€‚ | [AdapterDrop: On the Efficiency of Adapters in Transformers](https://arxiv.org/abs/2010.11918) |  |  | 
| MAM Adapter | MAM Adapterï¼Œä¸€ä¸ªåœ¨Adapterã€Prefix Tuningå’ŒLoRAä¹‹é—´å»ºç«‹è”ç³»çš„ç»Ÿä¸€æ–¹æ³•ã€‚æ¨¡å‹ MAM Adapter æ˜¯ç”¨ FFN å±‚çš„å¹¶è¡ŒAdapterå’Œè½¯æç¤ºçš„ç»„åˆã€‚ | [Towards a Unified View of Parameter-Efficient Transfer Learning](https://arxiv.org/abs/2110.04366) | [MAM Adapter Code](https://github.com/jxhe/unify-parameter-efficient-tuning) |  | 
| UniPELT | UniPELTæ–¹æ³•å°†ä¸åŒçš„PELTæ–¹æ³•ä½œä¸ºå­æ¨¡å—ï¼Œå¹¶é€šè¿‡é—¨æ§æœºåˆ¶å­¦ä¹ æ¿€æ´»æœ€é€‚åˆå½“å‰æ•°æ®æˆ–ä»»åŠ¡çš„æ–¹æ³•ã€‚ | [UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning](https://arxiv.org/abs/2110.07577) | [UniPELT Code](https://github.com/morningmoni/UniPELT) |  | 

è¿™é‡Œæ•´ç†å…³äºLLMå¾®è°ƒçš„è„šæœ¬ä»¥åŠå¼€æºå·¥å…·æˆ–è€…å¹³å°çš„ä½¿ç”¨æ¡ˆä¾‹ï¼Œæ›´å¤šè¯·å‚è€ƒã€[Fine Tune](https://github.com/ArronAI007/Awesome-AGI/blob/main/Open%20Tool/Fine-Tune/README.md)ã€‘

---

### LLM éƒ¨ç½²

| Description| Paper | Code | Blog |
| --- | --- | --- | --- |  
| BentoML |  | [BentoML Code](https://github.com/bentoml/BentoML) |  |  
| CLIP-API-service |  |  |  |  
| CTranslate2 |  |  |  |  
| DeepSpeed-MII |  |  |  | 
| FastLLM |  |  |  |   
| Huggingface |  |  |  |   
| JittorLLM |  |  |  |   
| LightLLM |  |  |  |  
| LMDeploy |  |  |  |  
| MLC LLM |  |  |  |  
| OneDiffusion |  |  |  |  
| OpenLLM |  |  |  |  
| Ray Serve |  |  |  |  

ã€LLMå¤§è¯­è¨€æ¨¡å‹ä¹‹Generate/Inferenceï¼ˆç”Ÿæˆ/æ¨ç†ï¼‰ä¸­å‚æ•°ä¸è§£ç ç­–ç•¥åŸç†åŠå…¶ä»£ç å®ç°ã€‘ã€[blog](https://mp.weixin.qq.com/s/BbWjr8mr3Iu_JLCK0x2rcA)ã€‘

---

### LLM åˆ†å¸ƒå¼å¹¶è¡Œæ¡†æ¶

| Description| Paper | Code | Blog |
| --- | --- | --- | --- |  
| ColossalAI |  | [ColossalAI Code](https://github.com/hpcaitech/ColossalAI) |  |  
| DeepSpeed |  |  |  |  
| Megatron-LM |  |  |  |  

---

## LLM åº”ç”¨

### RAG

#### RAGå®æˆ˜ä¸ç†è®º

RAGå®æˆ˜ä¸ç†è®ºç›¸å…³èµ„æ–™ï¼Œæ›´å¤šè¯·å‚è€ƒã€[LangChain](https://github.com/ArronAI007/Awesome-AGI/blob/main/RAG/README.md)ã€‘

RAGå®æˆ˜ä¸»è¦åˆ†ä¸ºLangChainæ¡†æ¶å®ç°å’ŒLlamaIndexæ¡†æ¶å®ç°ï¼Œåˆ†åˆ«å¯ä»¥å‚è€ƒ[LangChain_RAG](https://github.com/ArronAI007/Awesome-AGI/tree/main/RAG/LangChain_RAG)å’Œ[LlamaIndex_RAG](https://github.com/ArronAI007/Awesome-AGI/tree/main/RAG/LlamaIndex_RAG)

#### å‘é‡æ•°æ®åº“

| VectorDB| Paper | Code | Blog |
| --- | --- | --- | --- |  
| Chroma |  |  |  |  
| DingoDB |  | [dingo](https://github.com/dingodb/dingo)ï¼Œ[dingo-store](https://github.com/dingodb/dingo-store) | [DingoDBå®˜ç½‘](https://www.dingodb.com/) |  
| LanceDB |  |  |  |  
| Milvus |  |  |  |  
| Pinecone |  |  |  |  
| QDrant |  |  |  |  
| Weaviate |  |  |  |  
| Zilliz |  |  |  |  

---

#### RAGå¼€æºé¡¹ç›®

| RAG_OpenSoure_Tool | Code | Blog |
| --- | --- | --- |  
| AnythingLLM | [AnythingLLM Code](https://github.com/Mintplex-Labs/anything-llm) | [AnythingLLMå®˜ç½‘](https://useanything.com/) |  
| QAnything | [QAnything Code](https://github.com/netease-youdao/QAnything) |  |  

---

### Agent

| Model| Description | Code | Paper/Blog |
| --- | --- | --- | --- |  
| Agents |  | [Agent Code](https://github.com/aiwaves-cn/agents) | [Agents: An Open-source Framework for Autonomous Language Agents](https://arxiv.org/pdf/2309.07870.pdf)ï¼Œ[Agent å®˜ç½‘](http://www.aiwaves-agents.com/)ï¼Œ[blog](https://mp.weixin.qq.com/s/OEud_eW7kAMYW2PagdoIcg) |  
| AgentGPT |  | [AgentGPT Code](https://github.com/reworkd/AgentGPT) | [AgentGPT Chat](https://agentgpt.reworkd.ai/zh)ï¼Œ[AgentGPT docs](https://docs.reworkd.ai/introduction) | 
| AgentVerse |  |  |  |   
| AI Legion |  | [AI Legion Chat](https://github.com/eumemic/ai-legion) |  |  
| AutoGen | å¾®è½¯åœ¨å‘ OpenAI æ³¨èµ„ 130 äº¿ç¾å…ƒå¹¶ä½¿ Bing å˜å¾—æ›´æ™ºèƒ½åï¼Œç°åœ¨æˆä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸»è¦å‚ä¸è€…ã€‚å…¶ AutoGen æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘å’Œéƒ¨ç½²å¤šä¸ªä»£ç†çš„å¼€æºæ¡†æ¶ï¼Œè¿™äº›ä»£ç†å¯ä»¥å…±åŒå·¥ä½œä»¥è‡ªä¸»å®ç°ç›®æ ‡ã€‚AutoGen è¯•å›¾ä¿ƒè¿›å’Œç®€åŒ–ä»£ç†ä¹‹é—´çš„é€šä¿¡ï¼Œå‡å°‘é”™è¯¯ï¼Œå¹¶æœ€å¤§åŒ– LLMs çš„æ€§èƒ½ã€‚å®ƒè¿˜å…·æœ‰å¹¿æ³›çš„å®šåˆ¶åŠŸèƒ½ï¼Œå…è®¸æ‚¨é€‰æ‹©é¦–é€‰æ¨¡å‹ï¼Œé€šè¿‡äººç±»åé¦ˆæ”¹è¿›è¾“å‡ºï¼Œå¹¶åˆ©ç”¨é¢å¤–çš„å·¥å…·ã€‚ |  | [AutoGen blog](https://mp.weixin.qq.com/s/M7xHAA4HSH-cJG3kbvgvNg) |  
| AutoGPT | åˆ›å§‹äººæ‰˜å…°Â·å¸ƒé²æ–¯Â·ç†æŸ¥å…¹å¼€å‘ï¼ŒAutoGPT æ˜¯æ—©æœŸä»£ç†ä¹‹ä¸€ï¼Œäº 2023 å¹´ 3 æœˆå‘å¸ƒï¼Œæ˜¯æ ¹æ®ä¸­å²›çš„è®ºæ–‡å¼€å‘çš„ã€‚å®ƒä¹Ÿæ˜¯ä»Šå¤©åœ¨ GitHub ä¸Šæœ€å—æ¬¢è¿çš„ä»£ç†å­˜å‚¨åº“ã€‚ AutoGPT çš„ç†å¿µå¾ˆç®€å• - å®ƒæ˜¯ä¸€ä¸ªå®Œæ•´çš„å·¥å…·åŒ…ï¼Œç”¨äºæ„å»ºå’Œè¿è¡Œå„ç§é¡¹ç›®çš„å®šåˆ¶ AI ä»£ç†ã€‚è¯¥å·¥å…·ä½¿ç”¨ OpenAI çš„ GPT-4 å’Œ GPT-3.5 å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¹¶å…è®¸æ‚¨ä¸ºå„ç§ä¸ªäººå’Œå•†ä¸šé¡¹ç›®æ„å»ºä»£ç†ã€‚ | [AutoGPT Code](https://github.com/Significant-Gravitas/Auto-GPT) | [AutoGPT docs](https://docs.agpt.co/setup/) ï¼Œ[AutoGPT blog](https://generativeai.pub/complete-guide-to-setup-autogpt-revolutionize-your-task-automation-with-gpt-4-39eda5a85821?gi=ea5c40bac6fd) |  
| BabyAGI | BabyAGI æ˜¯ä¸­å±±çš„ä»»åŠ¡é©±åŠ¨è‡ªä¸»ä»£ç†çš„ç®€åŒ–ç‰ˆæœ¬ã€‚è¿™ä¸ª Python è„šæœ¬åªæœ‰ 140 ä¸ªä»£ç å­—ï¼Œå¹¶ä¸”æ ¹æ®å®˜æ–¹ GitHub ä»“åº“ï¼Œâ€œä½¿ç”¨ OpenAI å’ŒçŸ¢é‡æ•°æ®åº“ï¼Œå¦‚ Chroma æˆ– Weaviateï¼Œæ¥åˆ›å»ºã€ä¼˜å…ˆå¤„ç†å’Œæ‰§è¡Œä»»åŠ¡â€ã€‚ | [BabyAGI Code](https://github.com/yoheinakajima/babyagi) | [BabyAGI docs](https://babyagi.org/) |  
| Camel | è¯¥æ¡†æ¶åˆ©ç”¨ LLM çš„åŠ›é‡åŠ¨æ€åˆ†é…è§’è‰²ç»™ä»£ç†äººï¼ŒæŒ‡å®šå’Œå¼€å‘å¤æ‚ä»»åŠ¡ï¼Œå¹¶å®‰æ’è§’è‰²æ‰®æ¼”åœºæ™¯ï¼Œä»¥ä¿ƒè¿›ä»£ç†äººä¹‹é—´çš„åä½œã€‚è¿™å°±åƒæ˜¯ä¸ºäººå·¥æ™ºèƒ½è®¾è®¡çš„æˆå‰§ã€‚    | [CAMEL Code](https://github.com/camel-ai/camel) | [CAMEL Chat](http://agents.camel-ai.org/)ï¼Œ[CAMEL docs](https://www.camel-ai.org/) |  
| ChatDev | CoPilotã€Bardã€ChatGPT ç­‰ç­‰éƒ½æ˜¯å¼ºå¤§çš„ç¼–ç åŠ©æ‰‹ã€‚ä½†æ˜¯åƒ ChatDev è¿™æ ·çš„é¡¹ç›®å¯èƒ½å¾ˆå¿«å°±ä¼šè®©å®ƒä»¬æœ›å°˜è«åŠã€‚ChatDev è¢«æ‰“é€ æˆâ€œä¸€ä¸ªè™šæ‹Ÿè½¯ä»¶å…¬å¸â€ï¼Œå®ƒä¸ä»…ä½¿ç”¨ä¸€ä¸ªï¼Œè€Œæ˜¯å¤šä¸ªä»£ç†äººæ¥æ‰®æ¼”ä¼ ç»Ÿå¼€å‘ç»„ç»‡ä¸­çš„ä¸åŒè§’è‰²ã€‚  ä»£ç†äºº - æ¯ä¸ªéƒ½è¢«åˆ†é…äº†ä¸€ä¸ªç‹¬ç‰¹çš„è§’è‰² - å¯ä»¥åˆä½œå¤„ç†å„ç§ä»»åŠ¡ï¼Œä»è®¾è®¡è½¯ä»¶åˆ°ç¼–å†™ä»£ç å’Œæ–‡æ¡£ã€‚é›„å¿ƒå‹ƒå‹ƒï¼Ÿå½“ç„¶ã€‚ChatDev ä»ç„¶æ›´å¤šåœ°æ˜¯ä¸€ä¸ªä»£ç†äººäº’åŠ¨çš„æµ‹è¯•å¹³å°ï¼Œä½†å¦‚æœä½ è‡ªå·±æ˜¯å¼€å‘äººå‘˜ï¼Œå®ƒæ˜¯å€¼å¾—ä¸€çœ‹çš„ã€‚ | [ChatDev Code](https://github.com/OpenBMB/ChatDev) |  |  
| crewAI |  | [crewAI Code](https://github.com/joaomdmoura/crewAI) | [crewAI Blog](https://mp.weixin.qq.com/s/FBhrVwBlSMtfK1KTwo1yXg) |  
| CogAgent |  |  |  |  
| Do Anything Machine |  |  | [Do Anything Machine Chat](https://www.doanythingmachine.com/) |  
| Generative Agents |  | [GPTRPG Code](https://github.com/dzoba/gptrpg) | [Generative Agents: Interactive Simulacra of Human Behavior](https://arxiv.org/abs/2304.03442) | 
| Gentopia |  |  |  |  
| Godmode |  |  | [Godmode Chat](https://godmode.space/) |  
| GPT-Engineer |  | [GPT-Engineer Code](https://github.com/AntonOsika/gpt-engineer) |  |   
| HuggingGPT |  | [HuggingGPT Code](https://github.com/microsoft/JARVIS) | [HuggingGPT Chat](https://huggingface.co/spaces/microsoft/HuggingGPT) |  
| JARVIS | JARVIS è¿œä¸åŠæ‰˜å°¼Â·æ–¯å¡”å…‹æ ‡å¿—æ€§çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼ˆè¿˜æœ‰åŒæ ·æ ‡å¿—æ€§çš„ä¿ç½—Â·è´å¦å°¼çš„å£°éŸ³ï¼‰ï¼Œä½†å®ƒæœ‰ä¸€äº›å°æŠ€å·§ã€‚ä»¥ ChatGPT ä½œä¸ºå…¶â€œå†³ç­–å¼•æ“â€ï¼ŒJARVIS å¤„ç†ä»»åŠ¡è§„åˆ’ã€æ¨¡å‹é€‰æ‹©ã€ä»»åŠ¡æ‰§è¡Œå’Œå†…å®¹ç”Ÿæˆã€‚æ‹¥æœ‰å¯¹ HuggingFace å¹³å°ä¸Šæ•°åç§ä¸“é—¨æ¨¡å‹çš„è®¿é—®æƒé™ï¼ŒJARVIS åˆ©ç”¨ ChatGPT çš„æ¨ç†èƒ½åŠ›æ¥åº”ç”¨æœ€ä½³æ¨¡å‹åˆ°ç»™å®šçš„ä»»åŠ¡ä¸Šã€‚è¿™ä½¿å¾—å®ƒå¯¹å„ç§ä»»åŠ¡å…·æœ‰ç›¸å½“è¿·äººçš„çµæ´»æ€§ï¼Œä»ç®€å•çš„æ‘˜è¦åˆ°ç›®æ ‡æ£€æµ‹éƒ½èƒ½èƒœä»»ã€‚ | [JARVIS Code](https://github.com/microsoft/JARVIS) | --- |  
| LoopGPT | LoopGPT æ˜¯ Toran Bruce Richards çš„ AutoGPT çš„ä¸€ä¸ªè¿­ä»£ç‰ˆæœ¬ã€‚é™¤äº†ä¸€ä¸ªåˆé€‚çš„ Python å®ç°ï¼Œè¯¥æ¡†æ¶è¿˜å¸¦æ¥äº†å¯¹ GPT-3.5 çš„æ”¹è¿›æ”¯æŒï¼Œé›†æˆå’Œè‡ªå®šä¹‰ä»£ç†èƒ½åŠ›ã€‚å®ƒè¿˜æ¶ˆè€—æ›´å°‘çš„ API ä»¤ç‰Œï¼Œå› æ­¤è¿è¡Œæˆæœ¬æ›´ä½ã€‚LoopGPT å¯ä»¥åŸºæœ¬ä¸Šè‡ªä¸»è¿è¡Œï¼Œæˆ–è€…ä¸äººç±»ä¸€èµ·è¿è¡Œï¼Œä»¥æœ€å°åŒ–æ¨¡å‹çš„å¹»è§‰ã€‚æœ‰è¶£çš„æ˜¯ï¼Œè¯¥æ¡†æ¶ä¸éœ€è¦è®¿é—®å‘é‡æ•°æ®åº“æˆ–å¤–éƒ¨å­˜å‚¨æ¥ä¿å­˜æ•°æ®ã€‚å®ƒå¯ä»¥å°†ä»£ç†çŠ¶æ€å†™å…¥æ–‡ä»¶æˆ– Python é¡¹ç›®ã€‚ | [LoopGPT Code](https://github.com/farizrahman4u/loopgpt/tree/main) |  | 
| MetaGPT | MetaGPT æ˜¯å¦ä¸€ä¸ªå¼€æº AI ä»£ç†æ¡†æ¶ï¼Œè¯•å›¾æ¨¡ä»¿ä¼ ç»Ÿè½¯ä»¶å…¬å¸çš„ç»“æ„ã€‚ä¸ ChatDev ç±»ä¼¼ï¼Œä»£ç†è¢«åˆ†é…ä¸ºäº§å“ç»ç†ã€é¡¹ç›®ç»ç†å’Œå·¥ç¨‹å¸ˆçš„è§’è‰²ï¼Œå¹¶åä½œå®Œæˆç”¨æˆ·å®šä¹‰çš„ç¼–ç ä»»åŠ¡ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼ŒMetaGPT åªèƒ½å¤„ç†ä¸­ç­‰éš¾åº¦çš„ä»»åŠ¡ - æ¯”å¦‚ç¼–å†™è´ªåƒè›‡æ¸¸æˆæˆ–æ„å»ºç®€å•çš„å®ç”¨åº”ç”¨ç¨‹åº - ä½†å®ƒæ˜¯ä¸€ä¸ªæœ‰å‰é€”çš„å·¥å…·ï¼Œå¯èƒ½åœ¨æœªæ¥è¿…é€Ÿå‘å±•ã€‚ä½¿ç”¨ OpenAI API è´¹ç”¨ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´çš„é¡¹ç›®å¤§çº¦éœ€è¦ 2 ç¾å…ƒã€‚ | [MetaGPT Code](https://github.com/geekan/MetaGPT) |  | 
| NexusGPT |  |  | [NexusGPT Chat](https://nexus.snikpic.io/) |  
| OpenAGI | OpenAGI æ˜¯ä¸€ä¸ªå¼€æºçš„ AGIï¼ˆäººå·¥é€šç”¨æ™ºèƒ½ï¼‰ç ”ç©¶å¹³å°ï¼Œç»“åˆäº†å°å‹ä¸“å®¶æ¨¡å‹ - ä¸“é—¨é’ˆå¯¹æƒ…æ„Ÿåˆ†ææˆ–å›¾åƒå»æ¨¡ç³Šç­‰ä»»åŠ¡çš„æ¨¡å‹ - ä»¥åŠæ¥è‡ªä»»åŠ¡åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLTFï¼‰æ¥æ”¹è¿›å®ƒä»¬çš„è¾“å‡ºã€‚ åœ¨å¹•åï¼ŒOpenAGI ä¸å…¶ä»–è‡ªä¸»å¼€æº AI æ¡†æ¶å¹¶æ²¡æœ‰å¤ªå¤§çš„ä¸åŒã€‚å®ƒæ±‡é›†äº†åƒ ChatGPTã€LLMsï¼ˆå¦‚ LLaMa2ï¼‰å’Œå…¶ä»–ä¸“ä¸šæ¨¡å‹ç­‰æµè¡Œå¹³å°ï¼Œå¹¶æ ¹æ®ä»»åŠ¡çš„ä¸Šä¸‹æ–‡åŠ¨æ€é€‰æ‹©åˆé€‚çš„å·¥å…·ã€‚ | [OpenAGI Code](https://github.com/agiresearch/OpenAGI) |  |  
| RecurrentGPT |  |  |  |  
| RestGPT |  | [RestGPT Code](https://github.com/Yifan-Song793/RestGPT) | [RestGPT blog](https://mp.weixin.qq.com/s/cdkezgE31ozGPiLZBU9Cxw)ï¼Œ[RestGPT: Connecting Large Language Models with Real-World RESTful APIs](https://arxiv.org/abs/2306.06624) | 
| RoboGen |  | [RoboGen Code](https://github.com/Genesis-Embodied-AI) | [é¡¹ç›®ä¸»é¡µ](https://robogen-ai.github.io/)ï¼Œ[blog](https://mp.weixin.qq.com/s/2bQTuwE-k6ukp--XHXIzMg)ï¼Œ[RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation](https://arxiv.org/abs/2311.01455) | 
| ShortGPT | AI æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ä½†ç›´åˆ°æœ€è¿‘ï¼Œè§†é¢‘æ ¼å¼ä¸€ç›´å—åˆ°è¾ƒå°‘å…³æ³¨ã€‚ShortGPT æ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œå®ƒå…è®¸æ‚¨ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ¥ç®€åŒ–è¯¸å¦‚è§†é¢‘åˆ›ä½œã€è¯­éŸ³åˆæˆå’Œç¼–è¾‘ç­‰å¤æ‚ä»»åŠ¡ã€‚ ShortGPT å¯ä»¥å¤„ç†å¤§å¤šæ•°å…¸å‹çš„ä¸è§†é¢‘ç›¸å…³çš„ä»»åŠ¡ï¼Œå¦‚æ’°å†™è§†é¢‘è„šæœ¬ï¼Œç”Ÿæˆé…éŸ³ï¼Œé€‰æ‹©èƒŒæ™¯éŸ³ä¹ï¼Œæ’°å†™æ ‡é¢˜å’Œæè¿°ï¼Œç”šè‡³ç¼–è¾‘è§†é¢‘ã€‚è¯¥å·¥å…·é€‚ç”¨äºçŸ­è§†é¢‘å’Œé•¿è§†é¢‘å†…å®¹ï¼Œæ— è®ºå¹³å°å¦‚ä½•ã€‚ | [ShortGPT Code](https://github.com/RayVentura/ShortGPT) |  |    
| SuperAGI | SuperAGI æ˜¯ AutoGPT çš„æ›´çµæ´»ã€ç”¨æˆ·å‹å¥½çš„æ›¿ä»£å“ã€‚æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ªå¼€æº AI ä»£ç†çš„å‘å°„å°ï¼Œå®ƒåŒ…å«äº†æ„å»ºã€ç»´æŠ¤å’Œè¿è¡Œè‡ªå·±ä»£ç†æ‰€éœ€çš„ä¸€åˆ‡ã€‚è¿™è¿˜åŒ…æ‹¬æ’ä»¶å’Œä¸€ä¸ªäº‘ç‰ˆæœ¬ï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­æµ‹è¯•å„ç§åŠŸèƒ½ã€‚è¯¥æ¡†æ¶å…·æœ‰å¤šä¸ªäººå·¥æ™ºèƒ½æ¨¡å‹ï¼Œå›¾å½¢ç”¨æˆ·ç•Œé¢ï¼Œä¸å‘é‡æ•°æ®åº“çš„é›†æˆï¼ˆç”¨äºå­˜å‚¨/æ£€ç´¢æ•°æ®ï¼‰ï¼Œä»¥åŠæ€§èƒ½æ´å¯Ÿã€‚è¿˜æœ‰ä¸€ä¸ªå¸‚åœºï¼Œå…¶ä¸­æœ‰å·¥å…·åŒ…ï¼Œå¯ä»¥è®©æ‚¨å°†å…¶è¿æ¥åˆ°æµè¡Œçš„åº”ç”¨ç¨‹åºå’ŒæœåŠ¡ï¼Œå¦‚ Google Analyticsã€‚ | [SuperAGI Code](https://github.com/TransformerOptimus/SuperAGI) |  |  
| Toolformer |  |  | [Toolformer blog](https://www.sensorexpert.com.cn/article/194585.html)ï¼Œ[Toolformer: Language Models Can Teach Themselves to Use Tools](https://arxiv.org/pdf/2302.04761.pdf) |  
| XAgent |  | [XAgent Code](https://github.com/OpenBMB/XAgent) | [XAgentå®˜ç½‘](https://x-agent.net/)ï¼Œ[XAgent Blog](https://blog.x-agent.net) |  
| Xlang |  |  |  |  

---

### LLM åº”ç”¨æ¡†æ¶

#### LangChain

å…³äºLangChainçš„ç›¸å…³ç¬”è®°å’Œè¯¾ç¨‹ï¼Œæ›´å¤šè¯·å‚è€ƒã€[LangChain](https://github.com/ArronAI007/Awesome-AGI/tree/main/LangChain/README.md)ã€‘

LangSmithå…è®¸æ‚¨è°ƒè¯•ã€æµ‹è¯•ã€è¯„ä¼°å’Œç›‘æ§æ„å»ºåœ¨ä»»ä½•LLMæ¡†æ¶ä¸Šçš„é“¾å’Œæ™ºèƒ½ä»£ç†ï¼Œå¹¶ä¸LangChainæ— ç¼é›†æˆã€‚ã€[å¹³å°å…¥å£](https://www.langchain.com/langsmith)ã€‘ï¼Œã€[å®˜æ–¹æ–‡æ¡£åœ°å€](https://python.langchain.com/docs/langsmith/walkthrough)ã€‘ã€‚æ›´å¤šå®æˆ˜æ¡ˆä¾‹ä»£ç è¯·å‚è€ƒã€[LangSmithå®æˆ˜æ¡ˆä¾‹](https://github.com/ArronAI007/Awesome-AGI/tree/main/LangChain/LangSmith)ã€‘

LangFuseæ˜¯LangSmithçš„å¹³æ›¿ï¼Œã€[å®˜æ–¹ç½‘ç«™](https://langfuse.com/)ã€‘ï¼Œã€[é¡¹ç›®åœ°å€](https://github.com/langfuse)ã€‘ã€‚æ›´å¤šå®æˆ˜ä»£ç è¯·å‚è€ƒã€[LangFuse](https://github.com/ArronAI007/Awesome-AGI/tree/main/LangChain/LangFuse)ã€‘

---

#### LlamaIndex

æ•´ç†å…³äºLlamaIndexçš„ç›¸å…³ç¬”è®°å’Œè¯¾ç¨‹ï¼Œæ›´å¤šè¯·å‚è€ƒã€[LlamaIndex](https://github.com/ArronAI007/Awesome-AGI/blob/main/LlamaIndex/README.md)ã€‘

#### TaskingAI

æ•´ç†å…³äºTaskingAIçš„ç›¸å…³ç¬”è®°å’Œè¯¾ç¨‹ï¼Œæ›´å¤šè¯·å‚è€ƒã€[TaskingAI](https://github.com/ArronAI007/Awesome-AGI/blob/main/TaskingAI/README.md)ã€‘

---

## LLM Concepts

### Prompt Engineering

| FrameWork | Paper | Code | Blog |
| --- | --- | --- | --- |  
| AoT | [Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models](https://arxiv.org/abs/2308.10379) |  |  |  
| CoT | [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) |  |  |  
| CoTSC | [Self-Consistency Improves Chain of Thought Reasoning in Language Models](https://arxiv.org/abs/2203.11171) |  |  |  
| Cue-CoT | [Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs](https://arxiv.org/abs/2305.11792) | [Cue-CoT Code](https://github.com/ruleGreen/Cue-CoT) | [Cue-CoT blog](https://mp.weixin.qq.com/s/zJHZTuNPNc0jyj5OvvL3-g) |  
| GoT | [Graph of Thoughts: Solving Elaborate Problems with Large Language Models](https://arxiv.org/abs/2308.09687) |  |  |  
| PoT | [Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks](https://arxiv.org/abs/2211.12588) |  |  |  
| SoT | [Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding](https://arxiv.org/abs/2307.15337) |  |  |  
| ToT | [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) |  |  |  

æ›´å¤šè¯·å‚è€ƒã€[Prompt Engineering](https://github.com/ArronAI007/Awesome-AGI/tree/main/Prompt-Engineering/README.md)ã€‘

---

### RLHF

| Description| Paper | Code | Blog |
| --- | --- | --- | --- |  
| å¤ç°RLHFï¼šé€šè¿‡å¼€æºé¡¹ç›® trl æ­å»ºä¸€ä¸ªé€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆPPOï¼‰æ¥æ›´æ–°è¯­è¨€æ¨¡å‹ï¼ˆGPT-2ï¼‰ |  | [code](https://github.com/HarderThenHarder/transformers_tasks/tree/main/RLHF) | [blog](https://mp.weixin.qq.com/s/1v4Uuc1YAZ9MRr1UWMH9xw) |  
| è¯¦è§£å¤§æ¨¡å‹RLHFè¿‡ç¨‹ï¼ˆé…ä»£ç è§£è¯»ï¼‰ |  |  | [blog](https://mp.weixin.qq.com/s/2M3igy7Ctk2LAdNQLSO5tg) |  
| æƒ³è®­ç»ƒChatGPTï¼Ÿå¾—å…ˆå¼„æ˜ç™½Reward Modelæ€ä¹ˆè®­ï¼ˆé™„æºç ï¼‰ |  |  | [blog](https://mp.weixin.qq.com/s/1v4Uuc1YAZ9MRr1UWMH9xw) |  
| ç›´æ¥åå¥½ä¼˜åŒ–ç®—æ³•ï¼ˆDirect Preference Optimizationï¼ŒDPOï¼‰ | [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290) | [DPO Code](https://github.com/eric-mitchell/direct-preference-optimization) | [DPO Code](https://blog.csdn.net/chacha_/article/details/134527000) |  

---

### LLM æ‰©è¯è¡¨

ã€LLMå¤§æ¨¡å‹ä¹‹åŸºäºSentencePieceæ‰©å……LLaMaä¸­æ–‡è¯è¡¨å®è·µã€‘ã€[blog](https://mp.weixin.qq.com/s/N1mJ0gfDgNzztO55D-QNVg)ã€‘

---

### LLM é•¿æ–‡æœ¬

ç”±äºå¤§æ¨¡å‹å¤§éƒ¨åˆ†éƒ½æ˜¯åŸºäºTransformeræ¶æ„çš„ï¼Œè€ŒTransformerçš„äºŒæ¬¡å¤æ‚åº¦å¯¼è‡´å¤§æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦å—é™ï¼Œç„¶è€Œæœ€è¿‘å‡ºç°å¾ˆå¤šè°ƒæ•´Transformeræ¶æ„ï¼Œæ¯”å¦‚Mambaã€‚

| Description| Paper | Code | Blog |
| --- | --- | --- | --- |  
| Transformerå‡çº§ä¹‹è·¯ï¼šä¸€ç§å…¨å±€é•¿åº¦å¤–æ¨çš„æ–°æ€è·¯ |  |  | [blog](https://mp.weixin.qq.com/s/YJ647EUfzWaJsGoMdgsguA) |  
| ChatGPTèƒ½å†™é•¿ç¯‡å°è¯´äº†ï¼ŒETHæå‡ºRecurrentGPTå®ç°äº¤äº’å¼è¶…é•¿æ–‡æœ¬ç”Ÿæˆ | [paper](https://arxiv.org/abs/2305.13304) | [code](https://github.com/aiwaves-cn/RecurrentGPT) | [blog](https://mp.weixin.qq.com/s/5UVTwSWgoz7uhozMeps3EQ)ï¼Œ[demo1](https://www.aiwaves.org/recurrentgpt (é•¿ç¯‡å°è¯´å†™ä½œ))ï¼Œ[demo2](https://www.aiwaves.org/interactivefiction (äº¤äº’å¼å°è¯´)) |  
| è¯­è¨€å¤§æ¨¡å‹100Kä¸Šä¸‹æ–‡çª—å£çš„ç§˜è¯€ |  |  | [blog](https://mp.weixin.qq.com/s/_i0eQgYNSLJydv3qOTqr-Q) |  
| RoPEå¯èƒ½æ˜¯LLMæ—¶ä»£çš„Resnet |  |  | [blog](https://mp.weixin.qq.com/s/BVm1XC7r1yzOiWIrEbWg3A) |  
| å›¾è§£RoPEæ—‹è½¬ä½ç½®ç¼–ç åŠå…¶ç‰¹æ€§ |  |  | [blog](https://mp.weixin.qq.com/s/-1xVXjoM0imXMC7DKqo-Gw) |  
| è¯¦è§£åŸºäºè°ƒæ•´RoPEæ—‹è½¬è§’åº¦çš„å¤§æ¨¡å‹é•¿åº¦å¤–æ¨æ–¹æ³• |  |  | [blog](https://mp.weixin.qq.com/s/RtI95hu-ZLxGkdGuNIkERQ) | 
| æ— éœ€å¾®è°ƒçš„è‡ªæ‰©å±•å¤§æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£ | [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning](https://simg.baai.ac.cn/paperfile/a34ae7f4-f0ce-4f8f-b8f2-e8e4d84bbee5.pdf) | --- | --- |   
| å¤§æ¨¡å‹é•¿æ–‡æœ¬è¯„ä¼°æ–¹æ¡ˆCLongEval | [CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models](https://arxiv.org/pdf/2403.03514) | [CLongEval Code](https://github.com/zexuanqiu/CLongEval) | [CLongEval Blog](https://mp.weixin.qq.com/s/LuyanfotOGJhdUQ5fnUkqg) | 
| Infini-Transformer | []() |  |  |  
| MEGALODON | [MEGALODON: Efficient LLM Pretraining and Inference with Unlimited Context Length](https://arxiv.org/pdf/2404.08801.pdf) | [MEGALODON Code](https://github.com/XuezheMax/megalodon) | [MEGALODON Blog](https://mp.weixin.qq.com/s/UECqO_ijR8z1eTltSuc0SQ) |  
| LongRoPEï¼šå°†å¤§æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£æ‰©å±•è¶…è¿‡200ä¸‡tokens | [LongRoPE: Extending LLM context window beyond 2 million tokens](https://arxiv.org/pdf/2402.13753.pdf) |  | [LongRoPE Blog](https://mp.weixin.qq.com/s/SDX8IVuj2S6MgAhMAs6EbQ) |   

---

### LLM å¹»è§‰

è§£å†³å¹»è§‰å¸¸ç”¨çš„ä¸¤ç§æ–¹æ³•ï¼š1ï¼‰ä¸æ–­å¢åŠ æ¨¡å‹çš„æ•°æ®è§„æ¨¡ã€æå‡æ•°æ®è´¨é‡ï¼›2ï¼‰é€šè¿‡è°ƒç”¨æœç´¢ç­‰å¤–éƒ¨å·¥å…·è®©æ¨¡å‹èƒ½å¤Ÿè·å–å®æ—¶ä¿¡æ¯ã€‚

| Description| Paper | Code | Blog |
| --- | --- | --- | --- |  
| è…¾è®¯AILabç­‰ã€Šå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰ã€‹ï¼Œå…¨é¢é˜è¿°æ£€æµ‹ã€è§£é‡Šå’Œå‡è½»å¹»è§‰ | [Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models](https://www.zhuanzhi.ai/paper/61ebe9c5007cf1373b900452ad52f0ae) | [code](https://github.com/HillZhang1999/llm-hallucination-survey) | [blog](https://mp.weixin.qq.com/s/GrN0FO_HrEk4GMYdJWJCMQ) |  
| LLMå¹»è§‰çš„è§£å†³æ–¹æ¡ˆåŠå…¶åº”ç”¨ | [Cognitive Mirage: A Review of Hallucinations in Large Language Models](https://arxiv.org/abs/2309.06794v1) | [code](https://github.com/hongbinye/Cognitive-Mirage-Hallucinations-in-LLMs) | [blog](https://mp.weixin.qq.com/s/9yQeGk1mRgc9ityn5imxxw) |  

---

### LLM å¯æ§æ€§ä¸å®‰å…¨

| Description| Paper | Code | Blog |
| --- | --- | --- | --- |  
| å¾®è½¯æå‡ºControl-GPTï¼šç”¨GPT-4å®ç°å¯æ§æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼ | [paper](https://arxiv.org/abs/2305.18583) |  |  [blog](https://mp.weixin.qq.com/s/U3eWeGOEt9nhW-Xwbuah9w)|  
| AIGCå¦‚ä½•å®‰å…¨å¯æ§?ä¸­å±±å¤§å­¦ç­‰æœ€æ–°ã€ŠAIGCä¸­å¯¹éšç§å’Œå®‰å…¨çš„æŒ‘æˆ˜åŠå…¶è¡¥æ•‘æªæ–½ï¼šæ¢ç´¢éšç§è®¡ç®—ã€åŒºå—é“¾æ½œåœ¨åº”ç”¨ã€‹å…¨é¢é˜è¿° | [paper](https://www.zhuanzhi.ai/paper/0dd95e1d5aae9eb2e60aabf36a107482) |  | [blog](https://mp.weixin.qq.com/s/V8QjMQSO2tX6PFx_LfLIEA) |  
| ControlVideo: å¯æ§çš„Training-freeçš„æ–‡æœ¬ç”Ÿæˆè§†é¢‘ | [paper](https://arxiv.org/pdf/2305.13077.pdf) | [code](https://github.com/YBYBZhang/ControlVideo) | [blog](https://mp.weixin.qq.com/s/CAH6u-MT3cFM359d5_Xpxg) |  
| å¤§æ¨¡å‹åˆ‡è„‘åå˜èº«PoisonGPTï¼Œè™šå‡ä¿¡æ¯æ¡ˆä¾‹ |  | [code](https://colab.research.google.com/drive/16RPph6SobDLhisNzA5azcP-0uMGGq10R?usp=sharing&ref=blog.mithrilsecurity.io) | [blog](https://hub.baai.ac.cn/view/27736) |  
| ChatGPTç¾Šé©¼å®¶æ—å…¨æ²¦é™·ï¼CMUåšå£«å‡»ç ´LLMæŠ¤æ ï¼Œäººç±»æ¯ç­è®¡åˆ’è„±å£è€Œå‡º | [paper](https://arxiv.org/abs/2307.15043) | [code](https://github.com/llm-attacks/llm-attacks) | [blog](https://mp.weixin.qq.com/s/298nwP98UdRNybV2Fuo6Wg) |  

---

### LLM æ–‡æœ¬æ£€æµ‹

| Description| Paper | Code | Blog |
| --- | --- | --- | --- |  
| ç¾å›½éº»çœå¤§å­¦&è°·æ­Œç ”ç©¶é™¢ï¼šæ”¹å†™æ–‡æœ¬å¯ä»¥é¿å¼€AIç”Ÿæˆæ–‡æœ¬çš„æ£€æµ‹å™¨ï¼Œä½†æ£€ç´¢åˆ™æ˜¯ä¸€ç§æœ‰æ•ˆçš„é˜²å¾¡ | [paper](https://papers.labml.ai/api/v1/redirect/pdf?paper_key=2cfe8cecc9f211edb95839eec3084ddd) | [code](https://github.com/martiansideofthemoon/ai-detection-paraphrases) |  |  
| äººå·¥æ™ºèƒ½ç”Ÿæˆçš„æ–‡æœ¬èƒ½è¢«å¯é åœ°æ£€æµ‹å‡ºæ¥å—ï¼Ÿ | [paper](https://arxiv.org/pdf/2303.11156.pdf) |  | [blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247486128&idx=3&sn=e5ea32b7d7cb4c8c41f29a9ea15ac3ac&chksm=ced54954f9a2c0425a65761f1766550f6b90857da0106f6fd55f3c6773fbdbd1fc45bbb9369a&token=447941009&lang=zh_CN#rd) |  
| DetectGPTï¼ˆæ–¯å¦ç¦å¤§å­¦ï¼‰ï¼šåˆ©ç”¨æ¦‚ç‡æ›²ç‡æ£€æµ‹æ–‡æœ¬æ˜¯å¦å¤§æ¨¡å‹ç”Ÿæˆ | [paper](https://arxiv.org/abs/2301.11305) | [code&data](https://ericmitchell.ai/detectgpt/) | [blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485713&idx=2&sn=805caf25603cf15dbf71949f85b9d041&chksm=ced54af5f9a2c3e3e0dffd728592fd7ab8f738869e94240daba4fad9f6ac90a2f76a6b458e3f&token=447941009&lang=zh_CN#rd) |  
| Detecting LLM-Generated-Textç»¼è¿° | [paper](https://github.com/datamllab/The-Science-of-LLM-generated-Text-Detection) |  | [blog](https://mp.weixin.qq.com/s?__biz=Mzg3NDIyMzI0Mw==&mid=2247485747&idx=1&sn=5e5029a70c54c08f6f8c40631962b1e1&chksm=ced54ad7f9a2c3c184ccb123199510bb09470e054fb5cb887e70bac204927b65e296f8921db1&token=447941009&lang=zh_CN#rd) |  
| ä¸€ä¸ªä¸“ä¸º**æ•™è‚²**è€…æ‰“é€ çš„å…¨æ–° AI æ£€æµ‹æ¨¡å‹ |  |  | [blog](https://gptzero.substack.com/p/gptzerox) |  
| OpenAIé‡ç£…å‘å¸ƒå®˜æ–¹ã€ŒChatGPTæ£€æµ‹å™¨ã€ |  |  | [blog](https://mp.weixin.qq.com/s/EcZE7TgHspf22rPRWhAybw) |  
| æ–¯å¦ç¦æœ€æ–°ç ”ç©¶ï¼šä¸è¦è¿‡åº¦ä¾èµ–GPTç”Ÿæˆå†…å®¹ï¼Œå…¶æ£€æµ‹å™¨å¯èƒ½å­˜åœ¨ä¸åˆ©äºéæ¯è¯­è‹±è¯­å†™ä½œè€…çš„åè§ | [paper](https://arxiv.org/abs/2304.02819) |  |  |  
| TUMå‘å¸ƒæœ€æ–°ã€Šæ£€æµ‹ChatGPTç”Ÿæˆæ–‡æœ¬ç°çŠ¶ã€‹ç»¼è¿° | [paper](https://arxiv.org/abs/2309.07689) |  |  |  

---

## æ¬¢è¿å…±åˆ›

ã€ğŸ‘¬ğŸ»ã€‘æ¬¢è¿Star â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ && æäº¤ Pull requests ğŸ‘ğŸ»ğŸ‘ğŸ»ğŸ‘ğŸ»

## å…³äºæˆ‘

**ä¸ªäººä¸»é¡µ**ï¼šwshzd.github.io

**å¾®ä¿¡å…¬ä¼—å·**ï¼š

![å…¬ä¼—å·äºŒç»´ç ](https://i.postimg.cc/g092W4dB/ArronAI.jpg)

## å£°æ˜

ä»¥ä¸Šéƒ¨åˆ†èµ„æ–™æ¥è‡ªç½‘ç»œæ•´ç†ï¼Œä¾›å¤§å®¶å­¦ä¹ å‚è€ƒï¼Œå¦‚æœ‰ä¾µæƒï¼Œéº»çƒ¦è”ç³»æˆ‘åˆ é™¤ï¼ 

WeChatï¼šh18821656387
